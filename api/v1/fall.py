from fastapi import Depends, Query, HTTPException, Header
from fastapi import APIRouter, Request, Body
from fastapi.responses import StreamingResponse
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from typing import Optional
import time, json
import asyncio
import logging
import cv2
import numpy as np
from app.services.fall_detection_service import fall_warning, current_fall_status, update_fall_status

router = APIRouter()
from app.services.auth_service import get_current_user, User

logger = logging.getLogger(__name__)
security = HTTPBearer(auto_error=False)

async def get_user_for_stream(
    authorization: Optional[HTTPAuthorizationCredentials] = Depends(security),
    token: Optional[str] = Query(None, description="Token as query parameter")
):
    """ç‚ºå½±åƒä¸²æµæä¾›å½ˆæ€§çš„èªè­‰æ–¹å¼"""
    # å¦‚æœæœ‰ Authorization headerï¼Œä½¿ç”¨æ¨™æº–èªè­‰
    if authorization and authorization.credentials:
        try:
            class MockRequest:
                def __init__(self, token):
                    self.headers = {"authorization": f"Bearer {token}"}
            
            mock_request = MockRequest(authorization.credentials)
            return await get_current_user(mock_request)
        except Exception as e:
            logger.error(f"Token é©—è­‰å¤±æ•—: {e}")
            raise HTTPException(status_code=401, detail="ç„¡æ•ˆçš„èªè­‰ token")
    
    # å¦‚æœæœ‰ query parameter tokenï¼Œä¹Ÿå˜—è©¦èªè­‰
    elif token:
        try:
            class MockRequest:
                def __init__(self, token):
                    self.headers = {"authorization": f"Bearer {token}"}
            
            mock_request = MockRequest(token)
            return await get_current_user(mock_request)
        except Exception as e:
            logger.error(f"Query token é©—è­‰å¤±æ•—: {e}")
            raise HTTPException(status_code=401, detail="ç„¡æ•ˆçš„èªè­‰ token")
    
    else:
        raise HTTPException(status_code=401, detail="æœªæä¾›èªè­‰ token")

# æ·»åŠ å¯é¸èªè­‰çš„ç‰ˆæœ¬ï¼Œç”¨æ–¼å…§éƒ¨æœå‹™èª¿ç”¨
async def get_user_optional(
    authorization: Optional[HTTPAuthorizationCredentials] = Depends(security),
    token: Optional[str] = Query(None, description="Token as query parameter")
):
    """å¯é¸èªè­‰ - ç”¨æ–¼å…§éƒ¨æœå‹™èª¿ç”¨"""
    try:
        return await get_user_for_stream(authorization, token)
    except HTTPException:
        # å¦‚æœèªè­‰å¤±æ•—ï¼Œè¿”å›ä¸€å€‹æ¨¡æ“¬ç”¨æˆ¶ç”¨æ–¼å…§éƒ¨èª¿ç”¨
        class InternalUser:
            def __init__(self):
                self.username = "internal_service"
                self.email = "internal@system"
        return InternalUser()

@router.get("/fall_status")
async def get_fall_status():
    """è·Œå€’ç‹€æ…‹ç«¯é» - ç§»é™¤èªè­‰è¦æ±‚"""
    return current_fall_status

# ç§»é™¤é‡è¤‡çš„ /status è·¯ç”±ï¼Œåªä¿ç•™ä¸€å€‹ç„¡èªè­‰ç‰ˆæœ¬
@router.get("/status")
async def get_fall_status_alias():
    """è·Œå€’ç‹€æ…‹åˆ¥åè·¯ç”± - ç„¡éœ€èªè­‰ï¼Œä¾›å…§éƒ¨èª¿ç”¨"""
    return current_fall_status

# ç‚º 163.13.202.128 çš„è«‹æ±‚æ·»åŠ  /api/fall_status è·¯ç”±åˆ¥å
@router.get("/api/fall_status") 
async def get_fall_status_api_alias():
    """API è·¯å¾‘åˆ¥å - ç„¡éœ€èªè­‰ï¼Œä¾›å…§éƒ¨ç³»çµ±èª¿ç”¨"""
    return current_fall_status

# ç‚ºç›´æ¥çš„ /fall_status è«‹æ±‚æ·»åŠ ç„¡èªè­‰ç‰ˆæœ¬
@router.get("/fall_status_public")
async def get_fall_status_public():
    """å…¬é–‹çš„è·Œå€’ç‹€æ…‹ç«¯é» - ç„¡éœ€èªè­‰"""
    return current_fall_status

# æ·»åŠ æ›´å¤šç„¡èªè­‰çš„åˆ¥åè·¯ç”±
@router.get("/api/status")
async def get_api_status():
    """API ç‹€æ…‹ç«¯é» - ç„¡éœ€èªè­‰"""
    return current_fall_status

@router.get("/api/fall/status")
async def get_api_fall_status():
    """API Fall ç‹€æ…‹ç«¯é» - ç„¡éœ€èªè­‰"""
    return current_fall_status

@router.get("/history")
async def get_fall_history(limit: int = Query(30, description="é™åˆ¶è¿”å›çš„è¨˜éŒ„æ•¸é‡")):
    """ç²å–è·Œå€’æ­·å²è¨˜éŒ„ - ç§»é™¤èªè­‰è¦æ±‚"""
    try:
        # é€™è£¡æ‡‰è©²å¾è³‡æ–™åº«æˆ–æœå‹™ä¸­ç²å–æ­·å²è¨˜éŒ„
        # æš«æ™‚è¿”å›æ¨¡æ“¬è³‡æ–™
        history_data = []
        current_time = int(time.time())
        
        # ç”Ÿæˆä¸€äº›æ¨¡æ“¬çš„æ­·å²è³‡æ–™
        for i in range(min(limit, 10)):  # æœ€å¤šè¿”å›10ç­†æ¨¡æ“¬è³‡æ–™
            history_data.append({
                "id": i + 1,
                "fall_detected": i % 3 == 0,  # æ¯3ç­†æœ‰ä¸€ç­†è·Œå€’è¨˜éŒ„
                "timestamp": current_time - (i * 3600),  # æ¯å°æ™‚ä¸€ç­†è¨˜éŒ„
                "confidence": 0.85 if i % 3 == 0 else 0.12,
                "location": "å®¢å»³" if i % 2 == 0 else "è‡¥å®¤"
            })
        
        return {
            "status": "success",
            "data": history_data,
            "total": len(history_data)
        }
    except Exception as e:
        logger.error(f"ç²å–æ­·å²è¨˜éŒ„éŒ¯èª¤: {e}")
        return {
            "status": "error",
            "message": "ç„¡æ³•ç²å–æ­·å²è¨˜éŒ„",
            "data": [],
            "total": 0
        }

@router.post("/update")
async def update_fall(data: dict = Body(...), current_user: User = Depends(get_current_user)):
    is_fall = bool(data.get("fall", False))
    update_fall_status(is_fall)
    return {"msg": "ç‹€æ…‹å·²æ›´æ–°", "fall": is_fall}

@router.get("/events")
async def sse_events(request: Request, current_user: User = Depends(get_current_user)):
    async def event_stream():
        try:
            connection_start = time.time()
            last_heartbeat = time.time()
            
            while True:
                try:
                    # æª¢æŸ¥å®¢æˆ¶ç«¯æ˜¯å¦æ–·ç·š
                    if await request.is_disconnected():
                        logger.info("å®¢æˆ¶ç«¯å·²æ–·ç·š")
                        break
                    
                    # 5åˆ†é˜å¾Œè‡ªå‹•é—œé–‰é€£ç·š
                    if time.time() - connection_start > 300:
                        logger.info("é€£ç·šè¶…æ™‚ï¼Œé—œé–‰ä¸²æµ")
                        break
                    
                    current_time = time.time()
                    
                    # æ¯30ç§’ç™¼é€å¿ƒè·³
                    if current_time - last_heartbeat > 30:
                        yield f"event: heartbeat\ndata: {json.dumps({'type': 'heartbeat', 'ts': int(current_time)})}\n\n"
                        last_heartbeat = current_time
                    
                    # ç™¼é€è·Œå€’ç‹€æ…‹è³‡æ–™
                    data = current_fall_status.copy()
                    data["ts"] = int(current_time)
                    yield f"event: fall_status\ndata: {json.dumps(data)}\n\n"
                    
                    await asyncio.sleep(1)
                    
                except asyncio.CancelledError:
                    logger.info("SSE ä¸²æµè¢«å–æ¶ˆ")
                    break
                except Exception as e:
                    logger.error(f"SSE ä¸²æµéŒ¯èª¤: {e}")
                    yield f"event: error\ndata: {json.dumps({'error': 'ä¸²æµéŒ¯èª¤'})}\n\n"
                    break
                    
        except Exception as e:
            logger.error(f"SSE é€£ç·šéŒ¯èª¤: {e}")
        finally:
            logger.info("SSE ä¸²æµçµæŸ")
    
    return StreamingResponse(
        event_stream(), 
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Headers": "Cache-Control"
        }
    )

@router.get("/video_feed")
async def video_feed():
    """å½±åƒä¸²æµç«¯é» - å„ªå…ˆé¡¯ç¤ºæ¨¹è“æ´¾å¯¦éš›å½±åƒ"""
    import httpx
    
    async def generate_frames():
        connection_attempts = []
        
        try:
            # é¦–å…ˆå˜—è©¦é€£æ¥æ¨¹è“æ´¾çš„å¯¦éš›ä¸²æµ
            stream_urls = [
                'http://100.66.243.67/stream.mjpg',           # åŸå§‹ä¸²æµ
                'http://100.66.243.67/stream_processed.mjpg', # è™•ç†å¾Œä¸²æµ
            ]
            
            # å˜—è©¦é€£æ¥æ¨¹è“æ´¾ä¸²æµ
            for url in stream_urls:
                try:
                    logger.info(f"å˜—è©¦é€£æ¥æ¨¹è“æ´¾å¯¦éš›ä¸²æµ: {url}")
                    connection_attempts.append(f"æ­£åœ¨å˜—è©¦: {url}")
                    
                    async with httpx.AsyncClient(
                        timeout=httpx.Timeout(10.0, connect=5.0),
                        follow_redirects=True
                    ) as client:
                        async with client.stream(
                            'GET', 
                            url,
                            headers={
                                'User-Agent': 'Fall-Detection-WebApp/1.0',
                                'Accept': 'multipart/x-mixed-replace,image/jpeg,image/*'
                            }
                        ) as response:
                            if response.status_code == 200:
                                logger.info(f"âœ… æˆåŠŸé€£æ¥æ¨¹è“æ´¾å¯¦éš›ä¸²æµ: {url}")
                                connection_attempts.append(f"âœ… æˆåŠŸé€£æ¥: {url}")
                                
                                # ç›´æ¥è½‰ç™¼æ¨¹è“æ´¾çš„ä¸²æµ
                                try:
                                    async for chunk in response.aiter_bytes(8192):
                                        if chunk:
                                            yield chunk
                                except asyncio.CancelledError:
                                    logger.info("æ¨¹è“æ´¾ä¸²æµè¢«å®¢æˆ¶ç«¯å–æ¶ˆ")
                                    return
                                except Exception as e:
                                    logger.error(f"æ¨¹è“æ´¾ä¸²æµå‚³è¼¸éŒ¯èª¤: {e}")
                                    connection_attempts.append(f"âŒ å‚³è¼¸éŒ¯èª¤: {str(e)}")
                                    break
                                return  # å¦‚æœä¸²æµçµæŸï¼Œé€€å‡ºå‡½æ•¸
                            else:
                                error_msg = f"HTTP {response.status_code}"
                                logger.warning(f"âŒ æ¨¹è“æ´¾ä¸²æµå›æ‡‰éŒ¯èª¤ {url}: {error_msg}")
                                connection_attempts.append(f"âŒ HTTPéŒ¯èª¤ {url}: {error_msg}")
                                
                except asyncio.CancelledError:
                    logger.info("é€£æ¥æ¨¹è“æ´¾æ™‚è¢«å–æ¶ˆ")
                    return
                except httpx.ConnectTimeout as e:
                    error_msg = f"é€£æ¥è¶…æ™‚: {str(e)}"
                    logger.error(f"âŒ æ¨¹è“æ´¾é€£æ¥è¶…æ™‚ {url}: {error_msg}")
                    connection_attempts.append(f"âŒ é€£æ¥è¶…æ™‚ {url}: {error_msg}")
                    continue
                except httpx.ReadTimeout as e:
                    error_msg = f"è®€å–è¶…æ™‚: {str(e)}"
                    logger.error(f"âŒ æ¨¹è“æ´¾è®€å–è¶…æ™‚ {url}: {error_msg}")
                    connection_attempts.append(f"âŒ è®€å–è¶…æ™‚ {url}: {error_msg}")
                    continue
                except httpx.ConnectError as e:
                    error_msg = f"é€£æ¥æ‹’çµ•: {str(e)}"
                    logger.error(f"âŒ æ¨¹è“æ´¾é€£æ¥æ‹’çµ• {url}: {error_msg}")
                    connection_attempts.append(f"âŒ é€£æ¥æ‹’çµ• {url}: {error_msg}")
                    continue
                except Exception as e:
                    error_msg = f"æœªçŸ¥éŒ¯èª¤: {str(e)}"
                    logger.error(f"âŒ ç„¡æ³•é€£æ¥æ¨¹è“æ´¾ä¸²æµ {url}: {error_msg}")
                    connection_attempts.append(f"âŒ é€£æ¥å¤±æ•— {url}: {error_msg}")
                    continue
            
            # å¦‚æœç„¡æ³•é€£æ¥æ¨¹è“æ´¾ï¼Œç”Ÿæˆè©³ç´°çš„è¨ºæ–·å½±åƒ
            logger.warning("âŒ ç„¡æ³•é€£æ¥æ¨¹è“æ´¾ï¼Œé¡¯ç¤ºè¨ºæ–·å½±åƒ")
            
            frame_count = 0
            start_time = time.time()
            
            while True:
                try:
                    # ç”Ÿæˆè¨ºæ–·å½±åƒ
                    img = np.zeros((600, 800, 3), dtype=np.uint8)  # å¢åŠ ç•«å¸ƒå¤§å°
                    
                    # æ·»åŠ èƒŒæ™¯
                    cv2.rectangle(img, (0, 0), (800, 80), (50, 50, 50), -1)
                    
                    cv2.putText(img, f"Raspberry Pi Connection Failed", (50, 50), 
                              cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
                    
                    cv2.putText(img, f"Target: 100.66.243.67", (50, 100), 
                              cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 2)
                    
                    # é¡¯ç¤ºé€£æ¥å˜—è©¦æ­·å²
                    y_pos = 140
                    cv2.putText(img, "Connection Attempts:", (50, y_pos), 
                              cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
                    
                    for i, attempt in enumerate(connection_attempts[-6:]):  # åªé¡¯ç¤ºæœ€è¿‘6æ¬¡å˜—è©¦
                        y_pos += 30
                        color = (0, 255, 0) if "âœ…" in attempt else (0, 0, 255)
                        # æˆªæ–·éé•·çš„æ–‡å­—
                        display_text = attempt[:60] + "..." if len(attempt) > 60 else attempt
                        cv2.putText(img, display_text, (70, y_pos), 
                                  cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)
                    
                    # é¡¯ç¤ºé‡è©¦è³‡è¨Š
                    retry_in = 5 - (frame_count % 150) // 30
                    cv2.putText(img, f"Next retry in: {retry_in}s", (50, y_pos + 60), 
                              cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
                    
                    # è·Œå€’ç‹€æ…‹é¡¯ç¤º
                    fall_status = current_fall_status.get('fall', False)
                    status_text = 'FALL DETECTED' if fall_status else 'NORMAL'
                    status_color = (0, 0, 255) if fall_status else (0, 255, 0)
                    
                    cv2.putText(img, f"Fall Status: {status_text}", (50, y_pos + 100), 
                              cv2.FONT_HERSHEY_SIMPLEX, 0.8, status_color, 2)
                    
                    if fall_status:
                        # è·Œå€’è­¦å‘Šæ•ˆæœ
                        cv2.rectangle(img, (30, y_pos + 120), (770, y_pos + 160), (0, 0, 255), 3)
                        cv2.putText(img, "EMERGENCY ALERT!", (50, y_pos + 145), 
                                  cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
                    
                    # æ™‚é–“æˆ³è¨˜
                    cv2.putText(img, f"Time: {time.strftime('%Y-%m-%d %H:%M:%S')}", (50, y_pos + 180), 
                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
                    
                    # æ¯5ç§’é‡æ–°å˜—è©¦é€£æ¥
                    if frame_count % 150 == 0 and frame_count > 0:  # 5ç§’ * 30fps = 150 frames
                        logger.info("ğŸ”„ é‡æ–°å˜—è©¦é€£æ¥æ¨¹è“æ´¾...")
                        connection_attempts.append(f"ğŸ”„ é‡è©¦ {time.strftime('%H:%M:%S')}")
                        # é‡æ–°é–‹å§‹ï¼Œè€Œä¸æ˜¯éæ­¸èª¿ç”¨
                        break
                    
                    # å°‡å½±åƒç·¨ç¢¼ç‚º JPEG
                    ret, buffer = cv2.imencode('.jpg', img, [cv2.IMWRITE_JPEG_QUALITY, 85])
                    if not ret:
                        continue
                        
                    frame = buffer.tobytes()
                    
                    # è¿”å› multipart æ ¼å¼çš„å½±åƒä¸²æµ
                    yield (b'--frame\r\n'
                           b'Content-Type: image/jpeg\r\n\r\n' + frame + b'\r\n')
                    
                    frame_count += 1
                    await asyncio.sleep(0.033)  # ç´„ 30 FPS
                    
                except asyncio.CancelledError:
                    logger.info("å½±åƒç”Ÿæˆè¢«å–æ¶ˆ")
                    return
                except Exception as e:
                    logger.error(f"å½±åƒç”ŸæˆéŒ¯èª¤: {e}")
                    await asyncio.sleep(1)
                    
        except asyncio.CancelledError:
            logger.info("å½±åƒä¸²æµè¢«å–æ¶ˆ")
            return
        except Exception as e:
            logger.error(f"å½±åƒä¸²æµéŒ¯èª¤: {e}")
    
    return StreamingResponse(
        generate_frames(),
        media_type="multipart/x-mixed-replace; boundary=frame",
        headers={
            "Cache-Control": "no-cache, no-store, must-revalidate",
            "Pragma": "no-cache",
            "Expires": "0",
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Headers": "*"
        }
    )

# æ·»åŠ ç„¡éœ€èªè­‰çš„å½±åƒä¸²æµç«¯é»
@router.get("/video_feed_public")
async def video_feed_public():
    """å…¬é–‹å½±åƒä¸²æµç«¯é» - ç„¡éœ€èªè­‰"""
    async def generate_frames():
        try:
            frame_count = 0
            start_time = time.time()
            
            while True:
                try:
                    # ç”Ÿæˆæ¸¬è©¦å½±åƒ
                    img = np.zeros((480, 640, 3), dtype=np.uint8)
                    
                    # æ·»åŠ èƒŒæ™¯
                    cv2.rectangle(img, (0, 0), (640, 80), (50, 50, 50), -1)
                    
                    cv2.putText(img, f"Fall Detection Camera", (50, 50), 
                              cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
                    
                    cv2.putText(img, f"Public Stream", (50, 120), 
                              cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 2)
                    
                    cv2.putText(img, f"Frame: {frame_count}", (50, 160), 
                              cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                    cv2.putText(img, f"Uptime: {int(time.time() - start_time)}s", (50, 200), 
                              cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
                    
                    # è·Œå€’ç‹€æ…‹é¡¯ç¤º
                    fall_status = current_fall_status.get('fall', False)
                    status_text = 'FALL DETECTED' if fall_status else 'NORMAL'
                    status_color = (0, 0, 255) if fall_status else (0, 255, 0)
                    
                    cv2.putText(img, f"Status: {status_text}", (50, 240), 
                              cv2.FONT_HERSHEY_SIMPLEX, 0.8, status_color, 2)
                    
                    if fall_status:
                        # è·Œå€’è­¦å‘Šæ•ˆæœ
                        cv2.rectangle(img, (30, 260), (610, 300), (0, 0, 255), 3)
                        cv2.putText(img, "EMERGENCY ALERT!", (50, 285), 
                                  cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
                    
                    # æ™‚é–“æˆ³è¨˜
                    cv2.putText(img, f"Time: {time.strftime('%Y-%m-%d %H:%M:%S')}", (50, 320), 
                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
                    
                    # å°‡å½±åƒç·¨ç¢¼ç‚º JPEG
                    ret, buffer = cv2.imencode('.jpg', img, [cv2.IMWRITE_JPEG_QUALITY, 85])
                    if not ret:
                        continue
                        
                    frame = buffer.tobytes()
                    
                    # è¿”å› multipart æ ¼å¼çš„å½±åƒä¸²æµ
                    yield (b'--frame\r\n'
                           b'Content-Type: image/jpeg\r\n\r\n' + frame + b'\r\n')
                    
                    frame_count += 1
                    await asyncio.sleep(0.033)  # ç´„ 30 FPS
                    
                except Exception as e:
                    logger.error(f"å½±åƒç”ŸæˆéŒ¯èª¤: {e}")
                    await asyncio.sleep(1)
                    
        except Exception as e:
            logger.error(f"å½±åƒä¸²æµéŒ¯èª¤: {e}")
    
    return StreamingResponse(
        generate_frames(),
        media_type="multipart/x-mixed-replace; boundary=frame",
        headers={
            "Cache-Control": "no-cache, no-store, must-revalidate",
            "Pragma": "no-cache",
            "Expires": "0",
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Headers": "*"
        }
    )

# æ·»åŠ  API æ­·å²è¨˜éŒ„ç«¯é»
@router.get("/api/fall_history")
async def get_api_fall_history(limit: int = Query(30, description="é™åˆ¶è¿”å›çš„è¨˜éŒ„æ•¸é‡")):
    """API è·Œå€’æ­·å²è¨˜éŒ„ç«¯é» - ç„¡éœ€èªè­‰"""
    history_data = []
    current_time = int(time.time())
    
    # ç”Ÿæˆä¸€äº›æ¨¡æ“¬çš„æ­·å²è³‡æ–™
    for i in range(min(limit, 10)):  # æœ€å¤šè¿”å›10ç­†æ¨¡æ“¬è³‡æ–™
        history_data.append({
            "id": i + 1,
            "fall_detected": i % 3 == 0,  # æ¯3ç­†æœ‰ä¸€ç­†è·Œå€’è¨˜éŒ„
            "timestamp": current_time - (i * 3600),  # æ¯å°æ™‚ä¸€ç­†è¨˜éŒ„
            "confidence": 0.85 if i % 3 == 0 else 0.12,
            "location": "å®¢å»³" if i % 2 == 0 else "è‡¥å®¤"
        })
    
    return {
        "status": "success",
        "data": history_data,
        "total": len(history_data)
    }

# æ·»åŠ æ­·å²è¨˜éŒ„çš„åˆ¥åè·¯ç”±
@router.get("/fall_history")
async def get_fall_history_public(limit: int = Query(30, description="é™åˆ¶è¿”å›çš„è¨˜éŒ„æ•¸é‡")):
    """å…¬é–‹è·Œå€’æ­·å²è¨˜éŒ„ç«¯é» - ç„¡éœ€èªè­‰"""
    return await get_api_fall_history(limit)

# æ·»åŠ æ›´å¤šæ­·å²è¨˜éŒ„ç«¯é»åˆ¥å
@router.get("/api/api/fall_history")
async def get_api_api_fall_history(limit: int = Query(30, description="é™åˆ¶è¿”å›çš„è¨˜éŒ„æ•¸é‡")):
    """è™•ç†é‡è¤‡ API è·¯å¾‘çš„æ­·å²è¨˜éŒ„ç«¯é»"""
    return await get_api_fall_history(limit)

@router.get("/api/history")
async def get_api_history(limit: int = Query(30, description="é™åˆ¶è¿”å›çš„è¨˜éŒ„æ•¸é‡")):
    """API æ­·å²è¨˜éŒ„ç«¯é»åˆ¥å"""
    return await get_api_fall_history(limit)

@router.get("/fall/history")
async def get_fall_slash_history(limit: int = Query(30, description="é™åˆ¶è¿”å›çš„è¨˜éŒ„æ•¸é‡")):
    """Fall æ­·å²è¨˜éŒ„ç«¯é»åˆ¥å"""
    return await get_api_fall_history(limit)

@router.get("/")
async def root():
    """æ ¹è·¯å¾‘ - ç§»é™¤èªè­‰è¦æ±‚"""
    return current_fall_status

# æ·»åŠ å¥åº·æª¢æŸ¥ç«¯é»ï¼Œç„¡éœ€èªè­‰
@router.get("/health")
async def health_check():
    """å¥åº·æª¢æŸ¥ç«¯é» - ç„¡éœ€èªè­‰"""
    return {
        "status": "healthy",
        "service": "fall_detection",
        "timestamp": int(time.time()),
        "fall_status": current_fall_status
    }

# æ·»åŠ ç°¡åŒ–çš„ç‹€æ…‹ç«¯é»ï¼Œä¾›å…§éƒ¨æœå‹™ä½¿ç”¨
@router.get("/simple_status")
async def simple_status():
    """ç°¡åŒ–ç‹€æ…‹ç«¯é» - ç„¡éœ€èªè­‰ï¼Œä¾›å…§éƒ¨æœå‹™ä½¿ç”¨"""
    return {
        "fall": current_fall_status.get('fall', False),
        "confidence": current_fall_status.get('confidence', 0.0),
        "timestamp": int(time.time())
    }

# æ·»åŠ  CORS é æª¢è«‹æ±‚è™•ç†
@router.options("/{full_path:path}")
async def handle_options(full_path: str):
    """è™•ç†æ‰€æœ‰è·¯å¾‘çš„ CORS é æª¢è«‹æ±‚"""
    from fastapi.responses import Response
    return Response(
        content="",
        status_code=200,
        headers={
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Methods": "GET, POST, PUT, DELETE, OPTIONS",
            "Access-Control-Allow-Headers": "Content-Type, Authorization, X-Requested-With, Accept",
            "Access-Control-Max-Age": "86400"
        }
    )

# æ·»åŠ ä¸€å€‹é€šç”¨çš„éŒ¯èª¤è™•ç†ç«¯é»
@router.get("/debug/{path:path}")
async def debug_endpoint(path: str):
    """èª¿è©¦ç«¯é» - é¡¯ç¤ºè«‹æ±‚çš„è·¯å¾‘è³‡è¨Š"""
    return {
        "requested_path": path,
        "available_endpoints": [
            "/fall_status",
            "/status", 
            "/video_feed",
            "/video_proxy",
            "/health",
            "/test_raspberry_pi",
            "/api/fall_status",
            "/api/status"
        ],
        "timestamp": int(time.time())
    }

# ä»£ç†é ç«¯å½±åƒä¸²æµä»¥è§£æ±ºæ··åˆå…§å®¹å•é¡Œ - ç§»é™¤èªè­‰è¦æ±‚
@router.get("/video_proxy")
async def video_proxy():
    """ä»£ç†é ç«¯å½±åƒä¸²æµä»¥è§£æ±ºæ··åˆå…§å®¹å•é¡Œ - ç§»é™¤èªè­‰è¦æ±‚"""
    import httpx
    
    async def proxy_stream():
        try:
            # æ ¹æ“šæ¨¹è“æ´¾å¯¦éš›çš„ API ç«¯é»çµæ§‹æ›´æ–° URL
            stream_urls = [
                'http://100.66.243.67/stream.mjpg',           # åŸå§‹ä¸²æµ
                'http://100.66.243.67/stream_processed.mjpg', # è™•ç†å¾Œä¸²æµ  
                'http://100.66.243.67/video_feed',
                'http://100.66.243.67/mjpg_stream',
            ]
            
            for url in stream_urls:
                retry_count = 0
                max_retries = 2
                
                while retry_count < max_retries:
                    try:
                        logger.info(f"å˜—è©¦é€£æ¥æ¨¹è“æ´¾æ”å½±æ©Ÿä¸²æµ (ç¬¬ {retry_count + 1} æ¬¡) - URL: {url}")
                        
                        async with httpx.AsyncClient(
                            timeout=httpx.Timeout(30.0, connect=10.0),
                            follow_redirects=True
                        ) as client:
                            async with client.stream(
                                'GET', 
                                url,
                                headers={
                                    'User-Agent': 'Fall-Detection-Proxy/1.0',
                                    'Accept': 'multipart/x-mixed-replace,image/jpeg,image/*'
                                }
                            ) as response:
                                if response.status_code == 200:
                                    logger.info(f"æˆåŠŸé€£æ¥åˆ°æ¨¹è“æ´¾æ”å½±æ©Ÿä¸²æµ: {url}")
                                    try:
                                        async for chunk in response.aiter_bytes(8192):
                                            if chunk:
                                                yield chunk
                                    except asyncio.CancelledError:
                                        logger.info("ä»£ç†ä¸²æµè¢«å–æ¶ˆ")
                                        return
                                    return  # æˆåŠŸé€£æ¥ï¼ŒçµæŸå‡½æ•¸
                                else:
                                    logger.warning(f"æ¨¹è“æ´¾æ”å½±æ©Ÿå›æ‡‰éŒ¯èª¤ {url}: {response.status_code}")
                                    raise httpx.RequestError(f"HTTP {response.status_code}")
                                    
                    except asyncio.CancelledError:
                        logger.info("é€£æ¥è¢«å–æ¶ˆ")
                        return
                    except Exception as e:
                        logger.error(f"æ”å½±æ©Ÿé€£ç·šéŒ¯èª¤ {url} (å˜—è©¦ {retry_count + 1}/{max_retries}): {e}")
                        retry_count += 1
                        
                        if retry_count < max_retries:
                            await asyncio.sleep(retry_count * 2)
                        else:
                            break
            
            # æ‰€æœ‰ URL éƒ½å¤±æ•—ï¼Œç”ŸæˆéŒ¯èª¤å½±åƒ
            logger.error("æ‰€æœ‰æ¨¹è“æ´¾ä¸²æµ URL éƒ½é€£ç·šå¤±æ•—")
            while True:
                try:
                    img = np.zeros((480, 640, 3), dtype=np.uint8)
                    cv2.putText(img, "Camera Connection Failed", (80, 140), 
                              cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
                    cv2.putText(img, f"Target: 100.66.243.67", (80, 180), 
                              cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
                    cv2.putText(img, "Tried endpoints:", (80, 220), 
                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)
                    cv2.putText(img, "- /stream.mjpg", (80, 250), 
                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)
                    cv2.putText(img, "- /stream_processed.mjpg", (80, 280), 
                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)
                    cv2.putText(img, f"Time: {time.strftime('%H:%M:%S')}", (80, 320), 
                              cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
                    
                    ret, buffer = cv2.imencode('.jpg', img, [cv2.IMWRITE_JPEG_QUALITY, 80])
                    if ret:
                        frame = buffer.tobytes()
                        yield (b'--frame\r\n'
                               b'Content-Type: image/jpeg\r\n\r\n' + frame + b'\r\n')
                    
                    await asyncio.sleep(1)
                    
                except asyncio.CancelledError:
                    logger.info("éŒ¯èª¤å½±åƒç”Ÿæˆè¢«å–æ¶ˆ")
                    return
                except Exception as e:
                    logger.error(f"ç”ŸæˆéŒ¯èª¤å½±åƒå¤±æ•—: {e}")
                    await asyncio.sleep(5)
                    
        except asyncio.CancelledError:
            logger.info("ä»£ç†ä¸²æµè¢«å–æ¶ˆ")
            return
        except Exception as e:
            logger.error(f"ä»£ç†ä¸²æµéŒ¯èª¤: {e}")
    
    return StreamingResponse(
        proxy_stream(),
        media_type="multipart/x-mixed-replace; boundary=frame",
        headers={
            "Cache-Control": "no-cache, no-store, must-revalidate",
            "Pragma": "no-cache", 
            "Expires": "0",
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Headers": "*"
        }
    )

@router.get("/test_raspberry_pi")
async def test_raspberry_pi():
    """æ¸¬è©¦æ¨¹è“æ´¾é€£ç·šç‹€æ…‹"""
    import httpx
    
    try:
        async with httpx.AsyncClient(timeout=10.0) as client:
            # æ ¹æ“šæ¨¹è“æ´¾å¯¦éš›çš„ API ç«¯é»æ¸¬è©¦
            test_urls = [
                'http://100.66.243.67/stream.mjpg',           # åŸå§‹ä¸²æµ
                'http://100.66.243.67/stream_processed.mjpg', # è™•ç†å¾Œä¸²æµ
                'http://100.66.243.67/dashboard',             # ç›£æ§å„€è¡¨æ¿
                'http://100.66.243.67/api/fall_status',       # è·Œå€’ç‹€æ…‹
                'http://100.66.243.67/events',                # äº‹ä»¶æµ
                'http://100.66.243.67/api/health',            # å¥åº·æª¢æŸ¥
                'http://100.66.243.67/',                      # æ ¹è·¯å¾‘
            ]
            
            results = []
            for url in test_urls:
                try:
                    response = await client.get(url, timeout=5.0)
                    content_type = response.headers.get('content-type', '')
                    results.append({
                        "url": url,
                        "status": response.status_code,
                        "accessible": True,
                        "content_type": content_type,
                        "response_size": len(response.content),
                        "is_stream": 'multipart' in content_type.lower() or 'mjpeg' in content_type.lower()
                    })
                except Exception as e:
                    results.append({
                        "url": url,
                        "status": None,
                        "accessible": False,
                        "error": str(e)
                    })
            
            return {
                "raspberry_pi_ip": "100.66.243.67",
                "test_time": int(time.time()),
                "test_results": results,
                "recommended_stream_urls": [
                    "http://100.66.243.67/stream.mjpg",
                    "http://100.66.243.67/stream_processed.mjpg"
                ]
            }
            
    except Exception as e:
        return {
            "raspberry_pi_ip": "100.66.243.67",
            "test_time": int(time.time()),
            "error": str(e),
            "accessible": False
        }

@router.get("/system_info")
async def get_system_info():
    """ç²å–ç³»çµ±è³‡æºå’Œ GPU ä½¿ç”¨è³‡è¨Š"""
    import psutil
    import subprocess
    import os
    
    try:
        system_info = {
            "timestamp": int(time.time()),
            "cpu": {
                "count": psutil.cpu_count(),
                "usage": psutil.cpu_percent(interval=1),
                "load_avg": os.getloadavg() if hasattr(os, 'getloadavg') else None
            },
            "memory": {
                "total": psutil.virtual_memory().total // (1024**3),  # GB
                "available": psutil.virtual_memory().available // (1024**3),  # GB
                "usage_percent": psutil.virtual_memory().percent
            },
            "gpu": {
                "detected": False,
                "nvidia_available": False,
                "tensorflow_gpu": False,
                "details": []
            }
        }
        
        # æª¢æŸ¥ NVIDIA GPU
        try:
            result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total,memory.used,utilization.gpu', '--format=csv,noheader,nounits'], 
                                  capture_output=True, text=True, timeout=10)
            if result.returncode == 0:
                system_info["gpu"]["nvidia_available"] = True
                system_info["gpu"]["detected"] = True
                for line in result.stdout.strip().split('\n'):
                    if line.strip():
                        parts = line.split(', ')
                        if len(parts) >= 4:
                            system_info["gpu"]["details"].append({
                                "name": parts[0],
                                "memory_total": f"{parts[1]} MB",
                                "memory_used": f"{parts[2]} MB", 
                                "utilization": f"{parts[3]}%"
                            })
        except Exception as e:
            system_info["gpu"]["nvidia_error"] = str(e)
        
        # æª¢æŸ¥ TensorFlow GPU æ”¯æ´
        try:
            import tensorflow as tf
            system_info["tensorflow_version"] = tf.__version__
            gpus = tf.config.list_physical_devices('GPU')
            system_info["gpu"]["tensorflow_gpu"] = len(gpus) > 0
            system_info["gpu"]["tensorflow_gpus"] = [gpu.name for gpu in gpus]
        except Exception as e:
            system_info["tensorflow_error"] = str(e)
        
        # æª¢æŸ¥ OpenGL æ¸²æŸ“å™¨
        try:
            result = subprocess.run(['glxinfo', '-B'], capture_output=True, text=True, timeout=5)
            if result.returncode == 0:
                for line in result.stdout.split('\n'):
                    if 'OpenGL renderer string' in line:
                        system_info["opengl_renderer"] = line.split(':', 1)[1].strip()
                    elif 'OpenGL version string' in line:
                        system_info["opengl_version"] = line.split(':', 1)[1].strip()
        except Exception as e:
            system_info["opengl_error"] = str(e)
        
        return system_info
        
    except Exception as e:
        logger.error(f"ç²å–ç³»çµ±è³‡è¨ŠéŒ¯èª¤: {e}")
        return {
            "error": str(e),
            "timestamp": int(time.time())
        }

@router.get("/fall_detection_status")
async def get_fall_detection_status():
    """ç²å–è·Œå€’åµæ¸¬ç³»çµ±ç‹€æ…‹"""
    try:
        from app.services.fall_detection_service import current_fall_status
        
        # ç²å–è·Œå€’åµæ¸¬æœå‹™çš„è©³ç´°è³‡è¨Š
        status_info = current_fall_status.copy()
        status_info.update({
            "timestamp": int(time.time()),
            "service_info": {
                "model_loaded": True,  # æ ¹æ“šå¯¦éš›ç‹€æ³èª¿æ•´
                "camera_connected": False,  # æ ¹æ“šå¯¦éš›ç‹€æ³èª¿æ•´
                "processing_fps": 0,  # æ ¹æ“šå¯¦éš›ç‹€æ³èª¿æ•´
                "gpu_acceleration": False  # æ ¹æ“šå¯¦éš›ç‹€æ³èª¿æ•´
            }
        })
        
        # å˜—è©¦ç²å–æ¨¡çµ„çš„è©³ç´°è³‡è¨Š
        try:
            # é€™è£¡å¯èƒ½éœ€è¦æ ¹æ“šä½ çš„ fall_detection_service å¯¦éš›çµæ§‹èª¿æ•´
            import sys
            fall_modules = [name for name in sys.modules.keys() if 'fall' in name.lower()]
            status_info["loaded_modules"] = fall_modules
        except Exception as e:
            status_info["modules_error"] = str(e)
        
        return status_info
        
    except Exception as e:
        logger.error(f"ç²å–è·Œå€’åµæ¸¬ç‹€æ…‹éŒ¯èª¤: {e}")
        return {
            "error": str(e),
            "timestamp": int(time.time()),
            "fall": False,
            "confidence": 0.0
        }

@router.get("/gpu_acceleration_guide")
async def gpu_acceleration_guide():
    """GPU åŠ é€Ÿè¨­å®šæŒ‡å—"""
    import subprocess
    import os
    
    # æª¢æŸ¥ç•¶å‰ç³»çµ±ç‹€æ…‹
    current_status = {
        "gpu_available": False,
        "nvidia_driver": False,
        "cuda_available": False,
        "tensorflow_gpu": False,
        "current_renderer": "CPU (llvmpipe)"
    }
    
    # æª¢æŸ¥ GPU ç¡¬é«”
    try:
        result = subprocess.run(['lspci'], capture_output=True, text=True, timeout=10)
        gpu_info = []
        for line in result.stdout.split('\n'):
            if 'VGA' in line or 'NVIDIA' in line or 'Display' in line:
                gpu_info.append(line.strip())
        current_status["detected_hardware"] = gpu_info
    except:
        current_status["detected_hardware"] = ["ç„¡æ³•æª¢æ¸¬ç¡¬é«”"]
    
    # æª¢æŸ¥ NVIDIA é©…å‹•
    try:
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, timeout=5)
        current_status["nvidia_driver"] = result.returncode == 0
        if result.returncode == 0:
            current_status["nvidia_info"] = result.stdout.split('\n')[0:3]
    except:
        current_status["nvidia_driver"] = False
    
    # æª¢æŸ¥ CUDA
    try:
        result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True, timeout=5)
        current_status["cuda_available"] = result.returncode == 0
        if result.returncode == 0:
            current_status["cuda_version"] = result.stdout.strip()
    except:
        current_status["cuda_available"] = False
    
    # æª¢æŸ¥ TensorFlow GPU
    try:
        import tensorflow as tf
        gpus = tf.config.list_physical_devices('GPU')
        current_status["tensorflow_gpu"] = len(gpus) > 0
        current_status["tensorflow_version"] = tf.__version__
        current_status["available_gpus"] = [gpu.name for gpu in gpus]
    except:
        current_status["tensorflow_gpu"] = False
    
    return {
        "current_status": current_status,
        "setup_steps": {
            "step_1": {
                "title": "ğŸ” æª¢æŸ¥ GPU ç¡¬é«”",
                "description": "ç¢ºèªç³»çµ±æœ‰ NVIDIA GPU",
                "commands": [
                    "lspci | grep -i nvidia",
                    "lspci | grep -i vga"
                ],
                "expected": "æ‡‰è©²çœ‹åˆ° NVIDIA é¡¯ç¤ºå¡è³‡è¨Š"
            },
            "step_2": {
                "title": "ğŸš€ å®‰è£ NVIDIA é©…å‹•",
                "description": "å®‰è£é©ç•¶çš„ NVIDIA é©…å‹•ç¨‹å¼",
                "commands": [
                    "sudo apt update",
                    "sudo apt install nvidia-driver-470",  # æˆ–æ›´æ–°ç‰ˆæœ¬
                    "sudo reboot"
                ],
                "expected": "é‡é–‹æ©Ÿå¾Œ nvidia-smi æŒ‡ä»¤å¯æ­£å¸¸åŸ·è¡Œ"
            },
            "step_3": {
                "title": "âš¡ å®‰è£ CUDA Toolkit",
                "description": "å®‰è£ CUDA é–‹ç™¼å·¥å…·åŒ…",
                "commands": [
                    "sudo apt install nvidia-cuda-toolkit",
                    "export PATH=/usr/local/cuda/bin:$PATH",
                    "export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH"
                ],
                "expected": "nvcc --version æŒ‡ä»¤å¯æ­£å¸¸åŸ·è¡Œ"
            },
            "step_4": {
                "title": "ğŸ¤– å®‰è£ TensorFlow GPU",
                "description": "å®‰è£æ”¯æ´ GPU çš„ TensorFlow",
                "commands": [
                    "pip uninstall tensorflow",
                    "pip install tensorflow[and-cuda]",
                    # æˆ–è€…
                    "pip install tensorflow-gpu==2.12.0"
                ],
                "expected": "TensorFlow å¯ä»¥æª¢æ¸¬åˆ° GPU"
            },
            "step_5": {
                "title": "âœ… é©—è­‰ GPU è¨­å®š",
                "description": "ç¢ºèªæ‰€æœ‰çµ„ä»¶æ­£å¸¸é‹ä½œ",
                "commands": [
                    "nvidia-smi",
                    "python -c \"import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))\"",
                    "python -c \"import tensorflow as tf; print(tf.test.is_gpu_available())\""
                ],
                "expected": "æ‡‰è©²çœ‹åˆ° GPU è³‡è¨Šå’Œ True"
            }
        },
        "quick_setup_script": {
            "description": "ä¸€éµå®‰è£è…³æœ¬ (éœ€è¦ sudo æ¬Šé™)",
            "script": """#!/bin/bash
echo "ğŸš€ é–‹å§‹å®‰è£ GPU åŠ é€Ÿç’°å¢ƒ..."

# æ›´æ–°ç³»çµ±
sudo apt update

# å®‰è£ NVIDIA é©…å‹•
echo "ğŸ“¥ å®‰è£ NVIDIA é©…å‹•..."
sudo apt install -y nvidia-driver-470

# å®‰è£ CUDA
echo "âš¡ å®‰è£ CUDA..."
sudo apt install -y nvidia-cuda-toolkit

# è¨­å®šç’°å¢ƒè®Šæ•¸
echo "ğŸ”§ è¨­å®šç’°å¢ƒè®Šæ•¸..."
echo 'export PATH=/usr/local/cuda/bin:$PATH' >> ~/.bashrc
echo 'export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH' >> ~/.bashrc

# å®‰è£ TensorFlow GPU
echo "ğŸ¤– å®‰è£ TensorFlow GPU..."
pip uninstall -y tensorflow
pip install tensorflow[and-cuda]

echo "âœ… å®‰è£å®Œæˆï¼è«‹é‡æ–°å•Ÿå‹•ç³»çµ±ä»¥ç”Ÿæ•ˆã€‚"
echo "é‡å•Ÿå¾ŒåŸ·è¡Œï¼šnvidia-smi ä¾†ç¢ºèªé©…å‹•å®‰è£æˆåŠŸ"
""",
            "save_as": "install_gpu_acceleration.sh",
            "usage": "chmod +x install_gpu_acceleration.sh && ./install_gpu_acceleration.sh"
        },
        "troubleshooting": {
            "common_issues": [
                {
                    "problem": "nvidia-smi æŒ‡ä»¤æ‰¾ä¸åˆ°",
                    "solution": "é©…å‹•æœªæ­£ç¢ºå®‰è£ï¼Œé‡æ–°å®‰è£ nvidia-driver"
                },
                {
                    "problem": "TensorFlow æ‰¾ä¸åˆ° GPU",
                    "solution": "æª¢æŸ¥ CUDA ç‰ˆæœ¬ç›¸å®¹æ€§ï¼Œé‡æ–°å®‰è£æ­£ç¢ºç‰ˆæœ¬çš„ TensorFlow"
                },
                {
                    "problem": "CUDA out of memory",
                    "solution": "æ¸›å°‘æ‰¹æ¬¡å¤§å°æˆ–ä½¿ç”¨ tf.config.experimental.set_memory_growth"
                }
            ]
        }
    }

@router.get("/enable_gpu_acceleration")
async def enable_gpu_acceleration():
    """å˜—è©¦å•Ÿç”¨ GPU åŠ é€Ÿ"""
    try:
        import tensorflow as tf
        
        # æª¢æŸ¥ GPU å¯ç”¨æ€§
        gpus = tf.config.list_physical_devices('GPU')
        
        if not gpus:
            return {
                "success": False,
                "message": "æ²’æœ‰æª¢æ¸¬åˆ° GPU è¨­å‚™",
                "recommendation": "è«‹å…ˆå®‰è£ NVIDIA é©…å‹•å’Œ CUDA"
            }
        
        # è¨­å®š GPU è¨˜æ†¶é«”å¢é•·
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
        
        # æ¸¬è©¦ GPU é‹ç®—
        with tf.device('/GPU:0'):
            test_tensor = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])
            result = tf.matmul(test_tensor, test_tensor, transpose_b=True)
        
        return {
            "success": True,
            "message": "GPU åŠ é€Ÿå·²å•Ÿç”¨",
            "available_gpus": [gpu.name for gpu in gpus],
            "test_result": "GPU é‹ç®—æ¸¬è©¦æˆåŠŸ",
            "next_steps": [
                "é‡æ–°å•Ÿå‹•è·Œå€’åµæ¸¬æœå‹™ä»¥ä½¿ç”¨ GPU",
                "ç›£æ§ GPU ä½¿ç”¨ç‡ï¼šnvidia-smi"
            ]
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "message": "GPU å•Ÿç”¨å¤±æ•—",
            "troubleshooting": [
                "æª¢æŸ¥ NVIDIA é©…å‹•æ˜¯å¦æ­£ç¢ºå®‰è£",
                "ç¢ºèª CUDA å’Œ TensorFlow ç‰ˆæœ¬ç›¸å®¹æ€§",
                "é‡æ–°å®‰è£ tensorflow-gpu"
            ]
        }

@router.get("/benchmark_performance")
async def benchmark_performance():
    """æ•ˆèƒ½åŸºæº–æ¸¬è©¦ - CPU vs GPU"""
    import time
    import numpy as np
    
    try:
        import tensorflow as tf
        
        results = {
            "timestamp": int(time.time()),
            "tests": []
        }
        
        # CPU æ¸¬è©¦
        with tf.device('/CPU:0'):
            start_time = time.time()
            # æ¨¡æ“¬å½±åƒè™•ç†é‹ç®—
            data = tf.random.normal([100, 224, 224, 3])  # 100å¼µ 224x224 å½©è‰²å½±åƒ
            conv = tf.keras.layers.Conv2D(32, 3, activation='relu')
            result_cpu = conv(data)
            cpu_time = time.time() - start_time
            
        results["tests"].append({
            "device": "CPU",
            "time_seconds": cpu_time,
            "data_shape": [100, 224, 224, 3],
            "operation": "Conv2D processing"
        })
        
        # GPU æ¸¬è©¦ (å¦‚æœå¯ç”¨)
        gpus = tf.config.list_physical_devices('GPU')
        if gpus:
            with tf.device('/GPU:0'):
                start_time = time.time()
                data_gpu = tf.random.normal([100, 224, 224, 3])
                conv_gpu = tf.keras.layers.Conv2D(32, 3, activation='relu')
                result_gpu = conv_gpu(data_gpu)
                gpu_time = time.time() - start_time
                
            results["tests"].append({
                "device": "GPU",
                "time_seconds": gpu_time,
                "data_shape": [100, 224, 224, 3],
                "operation": "Conv2D processing"
            })
            
            # è¨ˆç®—åŠ é€Ÿæ¯”
            if gpu_time > 0:
                speedup = cpu_time / gpu_time
                results["performance_summary"] = {
                    "cpu_time": f"{cpu_time:.3f}s",
                    "gpu_time": f"{gpu_time:.3f}s",
                    "speedup": f"{speedup:.2f}x",
                    "recommendation": "ä½¿ç”¨ GPU" if speedup > 1.2 else "CPU å·²è¶³å¤ "
                }
        else:
            results["gpu_status"] = "GPU ä¸å¯ç”¨"
            
        return results
        
    except Exception as e:
        return {
            "error": str(e),
            "message": "æ•ˆèƒ½æ¸¬è©¦å¤±æ•—"
        }
