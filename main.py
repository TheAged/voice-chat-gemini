import schedule
import time
import sounddevice as sd
from scipy.io.wavfile import write
import whisper
import json
import re
import emoji
<<<<<<< HEAD
import numpy as np  # æ·»åŠ  numpy å°å…¥ä»¥æ”¯æ´èªéŸ³æ´»å‹•æª¢æ¸¬
from datetime import datetime, timedelta
import google.generativeai as genai
import edge_tts  
from emotion_module import detect_text_emotion, detect_audio_emotion, record_daily_emotion, multi_modal_emotion_detection
from emotion_config import get_current_config, CURRENT_MODE
import threading
import asyncio
import os
import platform
from dotenv import load_dotenv

# è·¨å¹³å°éŸ³æ•ˆå°å…¥
try:
    if platform.system() == "Windows":
        import winsound
    else:
        # Linux éŸ³æ•ˆæ›¿ä»£æ–¹æ¡ˆ
        winsound = None
except ImportError:
    winsound = None

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# åˆå§‹åŒ– Gemini Flash æ¨¡å‹
api_key = os.getenv("GOOGLE_API_KEY")
model_name = os.getenv("GEMINI_MODEL", "gemini-2.0-flash")

if not api_key:
    raise ValueError("è«‹åœ¨ .env æª”æ¡ˆä¸­è¨­å®š GOOGLE_API_KEY")

genai.configure(api_key=api_key)
model = genai.GenerativeModel(model_name)

# å¾ç’°å¢ƒè®Šæ•¸è®€å–æª”æ¡ˆè·¯å¾‘é…ç½®
ITEMS_FILE = os.getenv("ITEMS_FILE", "items.json")
SCHEDULE_FILE = os.getenv("SCHEDULE_FILE", "schedules.json")
AUDIO_PATH = os.getenv("AUDIO_PATH", "audio_input.wav")
CHAT_HISTORY_FILE = os.getenv("CHAT_HISTORY_FILE", "chat_history.json")
EMOTION_LOG_FILE = "emotions.json"

# å¾ç’°å¢ƒè®Šæ•¸è®€å– Whisper é…ç½®
whisper_model_size = os.getenv("WHISPER_MODEL", "base")
whisper_model = whisper.load_model(whisper_model_size)

# å¾ç’°å¢ƒè®Šæ•¸è®€å–éŸ³é »é…ç½®
AUDIO_SAMPLE_RATE = int(os.getenv("AUDIO_SAMPLE_RATE", "16000"))
AUDIO_DURATION = int(os.getenv("AUDIO_DURATION", "8"))

# å¾ç’°å¢ƒè®Šæ•¸è®€å– TTS é…ç½®
TTS_VOICE = os.getenv("TTS_VOICE", "zh-CN-XiaoxiaoNeural")
TTS_RATE = float(os.getenv("TTS_RATE", "1.0"))

# â”€â”€â”€â”€â”€â”€â”€ èªéŸ³æ§åˆ¶ç‹€æ…‹ â”€â”€â”€â”€â”€â”€â”€
is_playing_audio = False  # æ˜¯å¦æ­£åœ¨æ’­æ”¾èªéŸ³
audio_lock = threading.Lock()  # éŸ³é »äº’æ–¥é–

# â”€â”€â”€â”€â”€â”€â”€ å·¥å…·å‡½å¼ â”€â”€â”€â”€â”€â”€â”€
def clean_text_for_speech(text):
    """æ¸…ç†æ–‡å­—ä»¥ä¾›èªéŸ³åˆæˆä½¿ç”¨ï¼Œç§»é™¤æ¨™é»ç¬¦è™Ÿå’Œè¡¨æƒ…ç¬¦è™Ÿ"""
    # ç§»é™¤è¡¨æƒ…ç¬¦è™Ÿï¼ˆå¦‚æœæœ‰ emoji å¥—ä»¶ï¼‰
    try:
        text = emoji.replace_emoji(text, replace="")
    except:
        # å¦‚æœæ²’æœ‰ emoji å¥—ä»¶ï¼Œç”¨ regex ç§»é™¤å¸¸è¦‹è¡¨æƒ…ç¬¦è™Ÿ
        text = re.sub(r'[\U0001F600-\U0001F64F\U0001F300-\U0001F5FF\U0001F680-\U0001F6FF\U0001F1E0-\U0001F1FF\U00002702-\U000027B0\U000024C2-\U0001F251\U0001F900-\U0001F9FF]+', '', text)
    
    # ç§»é™¤æˆ–æ›¿æ›æ¨™é»ç¬¦è™Ÿ
    # ä¿ç•™å¥è™Ÿå’Œé€—è™Ÿä½œç‚ºåœé “ï¼Œä½†ç§»é™¤å…¶ä»–æ¨™é»
    text = re.sub(r'[ï¼!]', 'ã€‚', text)  # é©šå˜†è™Ÿè½‰å¥è™Ÿ
    text = re.sub(r'[ï¼Ÿ?]', 'ã€‚', text)  # å•è™Ÿè½‰å¥è™Ÿ
    text = re.sub(r'[ï¼›;]', 'ï¼Œ', text)  # åˆ†è™Ÿè½‰é€—è™Ÿ
    text = re.sub(r'[ï¼š:]', 'ï¼Œ', text)  # å†’è™Ÿè½‰é€—è™Ÿ
    text = re.sub(r'[""ã€Œã€ã€ã€]', '', text)  # ç§»é™¤å¼•è™Ÿ
    text = re.sub(r'[ï¼ˆï¼‰()ã€ã€‘\[\]]', '', text)  # ç§»é™¤æ‹¬è™Ÿ
    text = re.sub(r'[ï½~]', '', text)  # ç§»é™¤æ³¢æµªè™Ÿ
    text = re.sub(r'[â€¦]+', 'ã€‚', text)  # çœç•¥è™Ÿè½‰å¥è™Ÿ
    text = re.sub(r'[â€”\-â€“]+', 'ï¼Œ', text)  # ç ´æŠ˜è™Ÿè½‰é€—è™Ÿ
    text = re.sub(r'[Â·â€¢]', '', text)  # ç§»é™¤é …ç›®ç¬¦è™Ÿ
    
    # æ¸…ç†å¤šé¤˜çš„ç©ºæ ¼å’Œæ¨™é»
    text = re.sub(r'[ï¼Œã€‚]{2,}', 'ã€‚', text)  # å¤šå€‹æ¨™é»åˆä½µ
    text = re.sub(r'\s+', ' ', text)  # å¤šå€‹ç©ºæ ¼åˆä½µ
    text = text.strip()
    
    return text

=======
from datetime import datetime, timedelta
import google.generativeai as genai
import edge_tts  # æ–°å¢ Edge-TTS å¥—ä»¶
from emotion_module import detect_text_emotion, detect_audio_emotion
from flask import Flask, request, jsonify
from utils import safe_generate
import os



ITEMS_FILE = "items.json"
SCHEDULE_FILE = "schedules.json"
AUDIO_PATH = "audio_input.wav"
CHAT_HISTORY_FILE = "chat_history.json"
from emotion_module import log_emotion
EMOTION_LOG_FILE = "emotion_log.json"  
whisper_model = whisper.load_model("base")

app = Flask(__name__)

# å…¨åŸŸè¨Šæ¯ä½‡åˆ—
message_queue = []

# â”€â”€â”€â”€â”€â”€â”€ å·¥å…·å‡½å¼ â”€â”€â”€â”€â”€â”€â”€
>>>>>>> cdde5e3fc6d7bae51be920ccbd20fd218dfdeea1
def clean_text_from_stt(text):
    text = emoji.replace_emoji(text, replace="")  # ç§»é™¤ emoji
    text = re.sub(r"[^\w\s\u4e00-\u9fff.,!?ï¼ï¼Ÿã€‚]", "", text)  # ç§»é™¤éèªè¨€ç¬¦è™Ÿ
    return text.strip()

<<<<<<< HEAD
def safe_generate(prompt):
    try:
        return model.generate_content(prompt).text.strip()
    except Exception as e:
        if "429" in str(e):
            print("é”åˆ°APIé™åˆ¶ï¼Œç­‰å¾…60ç§’å¾Œé‡è©¦...")
            time.sleep(60)
            try:
                return model.generate_content(prompt).text.strip()
            except Exception as e2:
                print("å†æ¬¡å¤±æ•—ï¼š", e2)
                return None
        else:
            print("å‘¼å«éŒ¯èª¤ï¼š", e)
            return None

=======
>>>>>>> cdde5e3fc6d7bae51be920ccbd20fd218dfdeea1
def load_json(path):
    try:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except:
        return []

def save_json(path, data):
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

<<<<<<< HEAD
def detect_item_related(text):
    """æª¢æ¸¬æ˜¯å¦ç‚ºç‰©å“ç›¸é—œçš„èªå¥"""
    item_keywords = ["æ”¾åœ¨", "æ”¾åˆ°", "å­˜æ”¾", "æ”¶ç´", "æ±è¥¿åœ¨", "ç‰©å“åœ¨", "æ›¸åŒ…", "æ‰‹æ©Ÿ", "é‘°åŒ™", "éŒ¢åŒ…", "çœ¼é¡"]
    location_keywords = ["æˆ¿é–“", "æ¡Œå­", "æŠ½å±œ", "æ«ƒå­", "åºŠä¸Š", "æ²™ç™¼", "å»šæˆ¿", "å®¢å»³", "æ›¸æˆ¿"]
    
    text_lower = text.lower()
    has_item_keyword = any(keyword in text_lower for keyword in item_keywords)
    has_location_keyword = any(keyword in text_lower for keyword in location_keywords)
    
    return has_item_keyword or has_location_keyword

def detect_item_query(text):
    """æª¢æ¸¬æ˜¯å¦ç‚ºç‰©å“æŸ¥è©¢èªå¥"""
    query_keywords = ["åœ¨å“ª", "æ”¾å“ª", "å“ªè£¡", "åœ¨å“ªè£¡", "æ”¾åœ¨å“ª", "åœ¨ä»€éº¼åœ°æ–¹", "æ‰¾ä¸åˆ°"]
    item_keywords = ["æ›¸åŒ…", "æ‰‹æ©Ÿ", "é‘°åŒ™", "éŒ¢åŒ…", "çœ¼é¡", "æ±è¥¿", "ç‰©å“"]
    
    text_lower = text.lower()
    has_query_keyword = any(keyword in text_lower for keyword in query_keywords)
    has_item_keyword = any(keyword in text_lower for keyword in item_keywords)
    
    return has_query_keyword and has_item_keyword

def handle_item_query(text):
    """è™•ç†ç‰©å“æŸ¥è©¢è«‹æ±‚ï¼Œä¸»å‹•å»ºè­°å¯èƒ½åœ°é»"""
    prompt = f"""è«‹å¾ä¸‹é¢é€™å¥è©±ä¸­æ‰¾å‡ºä½¿ç”¨è€…æƒ³è¦æŸ¥è©¢çš„ç‰©å“åç¨±ï¼Œåªå›å‚³ç‰©å“åç¨±ï¼Œä¸è¦åŠ å…¶ä»–æ–‡å­—ï¼š
    å¥å­ï¼šã€Œ{text}ã€
    ä¾‹å¦‚ï¼šã€Œæˆ‘çš„æ›¸åŒ…åœ¨å“ªï¼Ÿã€â†’ æ›¸åŒ…
    """
    item_name = safe_generate(prompt)
    if not item_name:
        return "æŠ±æ­‰ï¼Œæˆ‘ç„¡æ³•ç†è§£ä½ è¦æŸ¥è©¢ä»€éº¼ç‰©å“ã€‚"
    item_name = item_name.strip().replace("ã€Œ", "").replace("ã€", "")

    # æŸ¥è©¢ç‰©å“è¨˜éŒ„
    records = load_json(ITEMS_FILE)
    found_items = [r for r in records if item_name in r.get('item', '') or r.get('item', '') in item_name]

    if found_items:
        # æ‰¾åˆ°æœ€æ–°çš„è¨˜éŒ„
        latest_record = max(found_items, key=lambda x: x.get('timestamp', ''))
        location = latest_record.get('location', 'æœªçŸ¥ä½ç½®')
        timestamp = latest_record.get('timestamp', '')
        # è§£ææ™‚é–“
        try:
            record_time = datetime.strptime(timestamp, "%Y-%m-%d %H:%M:%S")
            time_ago = datetime.now() - record_time
            if time_ago.days > 0:
                time_str = f"{time_ago.days}å¤©å‰"
            elif time_ago.seconds > 3600:
                hours = time_ago.seconds // 3600
                time_str = f"{hours}å°æ™‚å‰"
            else:
                minutes = time_ago.seconds // 60
                time_str = f"{minutes}åˆ†é˜å‰"
        except:
            time_str = "ä¹‹å‰"
        # ä¸»å‹•å»ºè­°
        response = (
            f"ä½ å¯ä»¥åˆ°ã€Œ{location}ã€æ‰¾æ‰¾çœ‹ä½ çš„ã€Œ{latest_record['item']}ã€ï¼Œ"
            "æ‰¾åˆ°å¾Œè¨˜å¾—æ”¾å›åŸæœ¬çš„ä½ç½®ã€‚å¦‚æœä½ æœ‰æ›åœ°æ–¹æ”¾ï¼Œè¨˜å¾—è·Ÿæˆ‘èªªä¸€è²ï¼Œæˆ‘æœƒå¹«ä½ è¨˜ä¸‹ä¾†ã€‚"
        )
        if len(found_items) > 1:
            response += f" æˆ‘ç¸½å…±æœ‰{len(found_items)}ç­†ç›¸é—œè¨˜éŒ„ã€‚"
        return response
    else:
        # æ²’æœ‰è¨˜éŒ„æ™‚ï¼Œå»ºè­°å¸¸è¦‹åœ°é»
        common_places = ["æµ´å®¤", "å®¢å»º", "åºŠé ­æ«ƒ", "å»šæˆ¿", "æ›¸æˆ¿"]
        suggestion = "ã€".join(common_places)
        return (
            f"æˆ‘æ²’æœ‰æ‰¾åˆ°ã€Œ{item_name}ã€çš„è¨˜éŒ„ã€‚ä½ å¯ä»¥å»{suggestion}ç­‰å¸¸ç”¨åœ°æ–¹æ‰¾æ‰¾çœ‹å–”ï¼"
            "å¦‚æœä½ æœ‰æ‰¾åˆ°ä¸¦æ›åœ°æ–¹æ”¾ï¼Œè¨˜å¾—è·Ÿæˆ‘èªªä¸€è²ï¼Œæˆ‘æœƒå¹«ä½ è¨˜ä¸‹ä¾†ã€‚"
        )

def detect_schedule_related(text):
    """æª¢æ¸¬æ˜¯å¦ç‚ºè¡Œç¨‹ç›¸é—œçš„èªå¥"""
    schedule_keywords = [
        # æ™‚é–“è©
        "æ˜å¤©", "å¾Œå¤©", "å¤§å¾Œå¤©", "ä¸‹é€±", "ä¸‹å€‹æœˆ", "ä»Šå¤©", "ä»Šæ™š", "æ™šä¸Š", "æ—©ä¸Š", "ä¸‹åˆ", "ä¸­åˆ",
        "é»", "åˆ†", "æ™‚å€™", "æ™‚é–“",
        # å‹•ä½œè©
        "è¦å»", "ç´„æœƒ", "æœƒè­°", "ä¸Šèª²", "å·¥ä½œ", "ç´„", "æé†’", "è¨˜å¾—", "å«æˆ‘", "é€šçŸ¥æˆ‘",
        "åƒè—¥", "ç¡è¦º", "èµ·åºŠ", "é–‹æœƒ", "ä¸Šç­", "ä¸‹ç­", "åƒé£¯", "çœ‹é†«ç”Ÿ",
        # åœ°é»è©
        "åœ¨å“ª", "å»å“ª", "åˆ°", "å›å®¶", "å‡ºé–€"
    ]
    
    text_lower = text.lower()
    # æª¢æŸ¥æ™‚é–“æ ¼å¼ (ä¾‹å¦‚: 11é»15åˆ†, 11:15)
    import re
    time_pattern = r'\d{1,2}[é»:]?\d{0,2}[åˆ†]?'
    has_time_format = bool(re.search(time_pattern, text))
    
    has_keyword = any(keyword in text_lower for keyword in schedule_keywords)
    
    return has_keyword or has_time_format

def detect_time_query(text):
    """æª¢æ¸¬æ˜¯å¦ç‚ºæ™‚é–“æŸ¥è©¢èªå¥"""
    time_query_keywords = [
        "ç¾åœ¨å¹¾é»", "å¹¾é»äº†", "ç¾åœ¨æ™‚é–“", "æ™‚é–“å¤šå°‘", "ä»€éº¼æ™‚å€™", "ç¾åœ¨æ˜¯", 
        "ä»Šå¤©å¹¾è™Ÿ", "ä»Šå¤©æ—¥æœŸ", "æ˜ŸæœŸå¹¾", "ç¦®æ‹œå¹¾", "ç¾åœ¨å¹¾æœˆ", "ç¾åœ¨å¹¾å¹´"
    ]
    
    text_lower = text.lower()
    return any(keyword in text_lower for keyword in time_query_keywords)

def handle_time_query(text):
    """è™•ç†æ™‚é–“æŸ¥è©¢è«‹æ±‚ï¼Œç›´æ¥å›å‚³ç•¶å‰æ™‚é–“è³‡è¨Š"""
    now = datetime.now()
    
    # æ ¹æ“šä¸åŒçš„æŸ¥è©¢å…§å®¹å›å‚³ä¸åŒçš„æ™‚é–“è³‡è¨Š
    if any(keyword in text for keyword in ["å¹¾é»", "æ™‚é–“"]):
        # æ™‚é–“æŸ¥è©¢
        hour = now.hour
        minute = now.minute
        
        # è½‰æ›ç‚º12å°æ™‚åˆ¶ä¸¦åŠ ä¸Šä¸­æ–‡æ™‚æ®µ
        if hour == 0:
            time_str = f"å‡Œæ™¨12é»{minute:02d}åˆ†"
        elif hour < 6:
            time_str = f"å‡Œæ™¨{hour}é»{minute:02d}åˆ†"
        elif hour < 12:
            time_str = f"æ—©ä¸Š{hour}é»{minute:02d}åˆ†"
        elif hour == 12:
            time_str = f"ä¸­åˆ12é»{minute:02d}åˆ†"
        elif hour < 18:
            time_str = f"ä¸‹åˆ{hour-12}é»{minute:02d}åˆ†"
        else:
            time_str = f"æ™šä¸Š{hour-12}é»{minute:02d}åˆ†"
            
        return f"ç¾åœ¨æ˜¯{time_str}"
    
    elif any(keyword in text for keyword in ["æ—¥æœŸ", "å¹¾è™Ÿ", "å¹¾æœˆ", "å¹¾å¹´"]):
        # æ—¥æœŸæŸ¥è©¢
        return f"ä»Šå¤©æ˜¯{now.strftime('%Yå¹´%mæœˆ%dæ—¥')}"
    
    elif any(keyword in text for keyword in ["æ˜ŸæœŸ", "ç¦®æ‹œ"]):
        # æ˜ŸæœŸæŸ¥è©¢
        weekdays = ['ä¸€', 'äºŒ', 'ä¸‰', 'å››', 'äº”', 'å…­', 'æ—¥']
        return f"ä»Šå¤©æ˜¯æ˜ŸæœŸ{weekdays[now.weekday()]}"
    
    else:
        # å®Œæ•´æ™‚é–“è³‡è¨Š
        hour = now.hour
        minute = now.minute
        weekdays = ['ä¸€', 'äºŒ', 'ä¸‰', 'å››', 'äº”', 'å…­', 'æ—¥']
        
        if hour == 0:
            time_str = f"å‡Œæ™¨12é»{minute:02d}åˆ†"
        elif hour < 6:
            time_str = f"å‡Œæ™¨{hour}é»{minute:02d}åˆ†"
        elif hour < 12:
            time_str = f"æ—©ä¸Š{hour}é»{minute:02d}åˆ†"
        elif hour == 12:
            time_str = f"ä¸­åˆ12é»{minute:02d}åˆ†"
        elif hour < 18:
            time_str = f"ä¸‹åˆ{hour-12}é»{minute:02d}åˆ†"
        else:
            time_str = f"æ™šä¸Š{hour-12}é»{minute:02d}åˆ†"
            
        return f"ç¾åœ¨æ˜¯{now.strftime('%Yå¹´%mæœˆ%dæ—¥')} æ˜ŸæœŸ{weekdays[now.weekday()]} {time_str}"

def detect_user_intent(text):
    """ä½¿ç”¨ AI æ™ºèƒ½åˆ¤æ–·ç”¨æˆ¶æ„åœ–"""
    
    # å…ˆæª¢æŸ¥æ˜¯å¦ç‚ºæ™‚é–“æŸ¥è©¢ï¼Œä¸éœ€è¦æ¶ˆè€— AI token
    if detect_time_query(text):
        return 5  # æ–°å¢æ™‚é–“æŸ¥è©¢æ„åœ–
    
    prompt = f"""è«‹åˆ†æä¸‹é¢é€™å¥è©±çš„ç”¨æˆ¶æ„åœ–ï¼Œåªå›å‚³ä¸€å€‹æ•¸å­—ï¼š
1 - èŠå¤©å°è©±ï¼ˆå•å€™ã€é–’èŠã€å•å•é¡Œç­‰ï¼‰
2 - è¨˜éŒ„ç‰©å“ä½ç½®ï¼ˆå‘Šè¨´æˆ‘æŸå€‹æ±è¥¿æ”¾åœ¨å“ªè£¡ï¼‰
3 - å®‰æ’æ™‚ç¨‹æé†’ï¼ˆè¦æˆ‘æé†’åšæŸä»¶äº‹ï¼‰
4 - æŸ¥è©¢ç‰©å“ä½ç½®ï¼ˆå•æˆ‘æŸå€‹æ±è¥¿åœ¨å“ªè£¡ï¼‰

å¥å­ï¼šã€Œ{text}ã€

ç¯„ä¾‹ï¼š
ã€Œä½ å¥½å—ï¼Ÿã€â†’ 1
ã€Œæˆ‘æŠŠé‘°åŒ™æ”¾åœ¨æ¡Œä¸Šã€â†’ 2
ã€Œæˆ‘çš„åŒ…åŒ…æ”¾åœ¨å¼Ÿå¼Ÿçš„æ¡Œä¸Šï¼Œå¹«æˆ‘è¨˜å¾—ä¸€ä¸‹ã€â†’ 2
ã€Œç­‰ç­‰20åˆ†æé†’æˆ‘åƒè—¥ã€â†’ 3
ã€Œæ˜å¤©9é»æé†’æˆ‘é–‹æœƒã€â†’ 3
ã€Œæˆ‘çš„æ‰‹æ©Ÿåœ¨å“ªï¼Ÿã€â†’ 4
ã€Œæ›¸åŒ…æ”¾åœ¨å“ªè£¡ï¼Ÿã€â†’ 4

é‡é»åˆ¤æ–·è¦å‰‡ï¼š
- å¦‚æœæåˆ°ç‰©å“ã€Œæ”¾åœ¨ã€æŸåœ°æ–¹ï¼Œä¸ç®¡æœ‰æ²’æœ‰èªªã€Œè¨˜å¾—ã€ï¼Œéƒ½æ˜¯è¨˜éŒ„ç‰©å“(2)
- åªæœ‰æ˜ç¢ºæåˆ°æ™‚é–“ï¼ˆå¹¾é»ã€å¹¾åˆ†ã€æ˜å¤©ç­‰ï¼‰ä¸¦è¦æ±‚æé†’ï¼Œæ‰æ˜¯å®‰æ’æé†’(3)
- å•ç‰©å“åœ¨å“ªè£¡ï¼Œæ˜¯æŸ¥è©¢ç‰©å“(4)

åªå›å‚³æ•¸å­—ï¼Œä¸è¦å…¶ä»–æ–‡å­—ï¼š"""
    
    result = safe_generate(prompt)
    if result and result.strip().isdigit():
        return int(result.strip())
    else:
        # å¦‚æœ AI åˆ¤æ–·å¤±æ•—ï¼Œå›åˆ°åŸæœ¬çš„é‚è¼¯
        if detect_item_query(text):
            return 4
        elif detect_item_related(text):
            return 2
        elif detect_schedule_related(text):
            return 3
        else:
            return 1

=======
>>>>>>> cdde5e3fc6d7bae51be920ccbd20fd218dfdeea1
def save_chat_log(user_input, ai_response):
    log = {
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "user": user_input,
        "response": ai_response
    }
    try:
        with open(CHAT_HISTORY_FILE, "r", encoding="utf-8") as f:
            records = json.load(f)
    except:
        records = []
    records.append(log)
    save_json(CHAT_HISTORY_FILE, records)

def save_emotion_log(text_emotion, audio_emotion):
<<<<<<< HEAD
    log = {
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "text_emotion": text_emotion,
        "audio_emotion": audio_emotion
    }
    try:
        with open(EMOTION_LOG_FILE, "r", encoding="utf-8") as f:
            records = json.load(f)
    except:
        records = []
    records.append(log)
    save_json(EMOTION_LOG_FILE, records)

async def handle_item_input(text):
=======
    # çµ±ä¸€å‘¼å« emotion_module.py çš„ log_emotionï¼Œåƒ…è¨˜éŒ„èåˆå¾Œçš„æœ€çµ‚æƒ…ç·’å»ºè­°æ–¼ fuse_emotions å…§å®Œæˆ
    # è‹¥ä»éœ€è¨˜éŒ„å–®ç¨æ¨¡æ…‹ï¼Œå¯è‡ªè¨‚æ ¼å¼
    log_emotion(text_emotion)
    log_emotion(audio_emotion)

def handle_item_input(text):
>>>>>>> cdde5e3fc6d7bae51be920ccbd20fd218dfdeea1
    """
    å¾æ–‡å­—ä¸­æå–ç‰©å“è³‡è¨Šä¸¦è¨˜éŒ„åˆ° JSON æª”æ¡ˆã€‚
    """
    prompt = f"""è«‹å¾ä¸‹é¢é€™å¥è©±ä¸­æ“·å–å‡ºä¸‹åˆ—è³‡è¨Šï¼Œç”¨ JSON æ ¼å¼å›è¦†ï¼š
    - itemï¼šç‰©å“åç¨±
    - locationï¼šæ”¾ç½®ä½ç½®
<<<<<<< HEAD
=======
    - ownerï¼šèª°çš„ï¼ˆå¦‚æœæ²’æåˆ°å°±å¡«ã€Œæˆ‘ã€ï¼‰
>>>>>>> cdde5e3fc6d7bae51be920ccbd20fd218dfdeea1
    å¥å­ï¼šã€Œ{text}ã€"""

    reply = safe_generate(prompt)

    if not reply:
        print("Gemini æ²’æœ‰å›æ‡‰ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚")
        return

    if reply.startswith("```"):
        reply = reply.strip("`").replace("json", "").strip()

    try:
        data = json.loads(reply)
    except:
        print(f"å›å‚³æ ¼å¼éŒ¯èª¤ï¼Œç„¡æ³•è§£æï¼š{reply}")
        return

    records = load_json(ITEMS_FILE)
    data["timestamp"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    records.append(data)
    save_json(ITEMS_FILE, records)

<<<<<<< HEAD
    print(f"å·²è¨˜éŒ„ï¼šã€Œ{data['item']}ã€æ”¾åœ¨ {data['location']}")

def parse_relative_time(text):
    """è§£æç›¸å°æ™‚é–“ä¸¦è½‰æ›ç‚ºå…·é«”æ™‚é–“"""
    now = datetime.now()

    # ä¸­æ–‡æ•¸å­—è½‰æ›å­—å…¸
    chinese_num_map = {
        'é›¶': 0, 'ä¸€': 1, 'äºŒ': 2, 'ä¸‰': 3, 'å››': 4, 'äº”': 5, 'å…­': 6, 'ä¸ƒ': 7, 'å…«': 8, 'ä¹': 9,
        'å': 10, 'åä¸€': 11, 'åäºŒ': 12, 'åä¸‰': 13, 'åå››': 14, 'åäº”': 15, 'åå…­': 16, 'åä¸ƒ': 17, 'åå…«': 18, 'åä¹': 19,
        'äºŒå': 20, 'ä¸‰å': 30, 'å››å': 40, 'äº”å': 50
    }
    
    def convert_chinese_number(text):
        """å°‡ä¸­æ–‡æ•¸å­—è½‰æ›ç‚ºé˜¿æ‹‰ä¼¯æ•¸å­—"""
        # è™•ç†ç°¡å–®çš„ä¸­æ–‡æ•¸å­—
        for chinese, num in chinese_num_map.items():
            text = text.replace(chinese, str(num))
        return text

    # å…ˆå°‡ä¸­æ–‡æ•¸å­—è½‰æ›ç‚ºé˜¿æ‹‰ä¼¯æ•¸å­—
    converted_text = convert_chinese_number(text)

    # å…ˆè™•ç†ç›¸å°æ™‚é–“ï¼šã€ŒXåˆ†é˜å¾Œã€ã€Œç­‰ç­‰Xåˆ†ã€ã€ŒXåˆ†å¾Œã€é€™é¡èªå¥
    # ä½†è¦é¿å…åŒ¹é…åˆ°æ™‚é–“æ ¼å¼ä¸­çš„åˆ†é˜ï¼ˆå¦‚ 7é»48åˆ†ï¼‰å’Œã€ŒXåˆ†çš„æ™‚å€™ã€
    min_match = re.search(r'(?:ç­‰ç­‰)?(\d{1,3})\s*åˆ†(?:é˜)?(?:å¾Œ|é’Ÿå¾Œ)(?!çš„æ—¶å€™|çš„æ™‚å€™)', converted_text)
    if not min_match:
        # æª¢æŸ¥æ˜¯å¦æ˜¯"ç­‰ç­‰Xåˆ†"çš„æ ¼å¼ï¼ˆç›¸å°æ™‚é–“ï¼Œä¸æ˜¯æ™‚é–“é»æ ¼å¼ï¼‰
        min_match = re.search(r'ç­‰ç­‰(\d{1,3})\s*åˆ†(?!é˜)(?!çš„æ—¶å€™|çš„æ™‚å€™)', converted_text)
    
    if min_match and not any(word in text for word in ["ä»Šå¤©", "æ˜å¤©", "å¾Œå¤©", "å¤§å¾Œå¤©", "ä¸‹é€±", "ä¸‹å€‹æœˆ"]) and not re.search(r'\d+[é»:]\d+', converted_text):
        minutes = int(min_match.group(1))
        target_time = now + timedelta(minutes=minutes)
        return target_time.strftime("%Y-%m-%d %H:%M")
    
    # ç„¶å¾Œè™•ç†ã€ŒXåˆ†çš„æ™‚å€™ã€é€™é¡è¡¨ç¤ºå…·é«”åˆ†é˜æ•¸çš„èªå¥ï¼ˆçµ•å°æ™‚é–“ï¼‰
    # ä½†å¦‚æœæœ‰"ç­‰ç­‰"å‰ç¶´ï¼Œå„ªå…ˆç•¶ä½œç›¸å°æ™‚é–“è™•ç†
    minute_point_match = re.search(r'(\d{1,2})\s*åˆ†(?:çš„æ—¶å€™|çš„æ™‚å€™)', converted_text)
    if minute_point_match:
        target_minute = int(minute_point_match.group(1))
        if target_minute <= 59:  # ç¢ºä¿åˆ†é˜æ•¸æœ‰æ•ˆ
            # å¦‚æœæœ‰"ç­‰ç­‰"ï¼Œç•¶ä½œç›¸å°æ™‚é–“è™•ç†
            if "ç­‰ç­‰" in converted_text:
                target_time = now + timedelta(minutes=target_minute)
                return target_time.strftime("%Y-%m-%d %H:%M")
            else:
                # è¨­å®šç‚ºç•¶å‰å°æ™‚çš„æŒ‡å®šåˆ†é˜
                target_time = now.replace(minute=target_minute, second=0, microsecond=0)
                # å¦‚æœè©²æ™‚é–“å·²ç¶“éäº†ï¼Œè¨­ç‚ºä¸‹ä¸€å°æ™‚çš„ç›¸åŒåˆ†é˜
                if target_time <= now:
                    target_time += timedelta(hours=1)
                return target_time.strftime("%Y-%m-%d %H:%M")

    # è§£æä»Šå¤©çš„æ™‚é–“ï¼ˆæ²’æœ‰æ˜ç¢ºèªªæ˜æ—¥æœŸçš„æƒ…æ³ï¼Œé è¨­ç‚ºä»Šå¤©ï¼‰
    time_match = re.search(r'(\d{1,2})[é»:](\d{1,2})', converted_text)
    if time_match:
        hour = int(time_match.group(1))
        minute = int(time_match.group(2))

        # æª¢æŸ¥æ˜¯å¦æ˜ç¢ºæåˆ°"æ˜å¤©"
        if "æ˜å¤©" in text:
            # å¦‚æœæ˜å¤©ä¹Ÿæœ‰ä¸‹åˆï¼Œéœ€è¦è½‰æ›æ™‚é–“
            if "ä¸‹åˆ" in text and hour <= 12:
                if hour == 12:
                    # ä¸‹åˆ12é»å°±æ˜¯ä¸­åˆ12é»ï¼Œä¿æŒ12
                    pass
                elif hour < 12:
                    # ä¸‹åˆ3é» = 15é»
                    hour += 12
            # å¦‚æœæ˜å¤©ä¹Ÿæœ‰æ™šä¸Šï¼Œéœ€è¦è½‰æ›æ™‚é–“
            elif "æ™šä¸Š" in text and hour <= 12:
                if hour == 12:
                    # æ™šä¸Š12é»å°±æ˜¯åˆå¤œï¼Œå³0é»
                    hour = 0
                elif hour < 12:
                    # æ™šä¸Š7é» = 19é»
                    hour += 12
            tomorrow = now + timedelta(days=1)
            target_time = tomorrow.replace(hour=hour, minute=minute, second=0, microsecond=0)
            return target_time.strftime("%Y-%m-%d %H:%M")

        # æª¢æŸ¥æ˜¯å¦æ˜ç¢ºæåˆ°"ä»Šå¤©"ã€"ä»Šæ™š"ã€"æ™šä¸Š"ã€"ä¸‹åˆ"ï¼Œæˆ–è€…æ²’æœ‰æ˜ç¢ºæ—¥æœŸ
        elif "ä»Šå¤©" in text or "ä»Šæ™š" in text or "æ™šä¸Š" in text or "ä¸‹åˆ" in text or ("æ˜å¤©" not in text and "å¾Œå¤©" not in text):
            # å¦‚æœæ˜ç¢ºæåˆ°"ä¸‹åˆ"ä¸”å°æ™‚æ•¸ <= 12ï¼Œç›´æ¥è½‰ç‚º24å°æ™‚åˆ¶
            if "ä¸‹åˆ" in text and hour <= 12:
                if hour == 12:
                    # ä¸‹åˆ12é»å°±æ˜¯ä¸­åˆ12é»ï¼Œä¿æŒ12
                    pass
                elif hour < 12:
                    # ä¸‹åˆ3é» = 15é»
                    hour += 12
                target_time = now.replace(hour=hour, minute=minute, second=0, microsecond=0)
                return target_time.strftime("%Y-%m-%d %H:%M")
            # å¦‚æœæ˜ç¢ºæåˆ°"æ™šä¸Š"ä¸”å°æ™‚æ•¸ <= 12ï¼Œç›´æ¥è½‰ç‚º24å°æ™‚åˆ¶
            elif "æ™šä¸Š" in text and hour <= 12:
                if hour == 12:
                    # æ™šä¸Š12é»å°±æ˜¯åˆå¤œï¼Œå³0é»
                    hour = 0
                elif hour < 12:
                    # æ™šä¸Š7é» = 19é»
                    hour += 12
                # æ™šä¸Šæ™‚é–“ç›´æ¥è¿”å›ï¼Œä¸é€²è¡Œé€²ä¸€æ­¥è™•ç†
                target_time = now.replace(hour=hour, minute=minute, second=0, microsecond=0)
                return target_time.strftime("%Y-%m-%d %H:%M")
            
            target_time = now.replace(hour=hour, minute=minute, second=0, microsecond=0)

            # å¦‚æœæ²’æœ‰æ˜ç¢ºæåˆ°"æ™šä¸Š"ï¼Œæ™ºèƒ½è™•ç†12å°æ™‚åˆ¶
            if target_time <= now and hour <= 12:
                # å„ªå…ˆæª¢æŸ¥æ˜¯å¦ç‚ºç•¶å¤©æ™šä¸Šæ™‚é–“ï¼ˆåŠ 12å°æ™‚ï¼‰
                if hour < 12:  # é¿å…12é»é‡è¤‡åŠ 12
                    evening_time = now.replace(hour=hour + 12, minute=minute, second=0, microsecond=0)
                    # å¦‚æœæ™šä¸Šæ™‚é–“é‚„æ²’åˆ°ï¼Œä½¿ç”¨æ™šä¸Šæ™‚é–“
                    if evening_time > now:
                        return evening_time.strftime("%Y-%m-%d %H:%M")
                    # å¦‚æœæ™šä¸Šæ™‚é–“ä¹Ÿéäº†ï¼Œä½†åœ¨1å°æ™‚å…§ï¼Œä»ç„¶ä½¿ç”¨ä»Šå¤©æ™šä¸Šçš„æ™‚é–“
                    elif (now - evening_time).total_seconds() <= 3600:  # 1å°æ™‚å…§
                        return evening_time.strftime("%Y-%m-%d %H:%M")

                # å¦‚æœä»¥ä¸Šéƒ½ä¸ç¬¦åˆï¼Œè¨­ç‚ºæ˜å¤©
                target_time += timedelta(days=1)

            return target_time.strftime("%Y-%m-%d %H:%M")

    # è™•ç†åªæœ‰æ™‚é–“ï¼Œæ²’æœ‰å…·é«”æ—¥æœŸçš„æƒ…æ³ï¼ˆä¸”å‰é¢æ²’æœ‰åŒ¹é…åˆ°å®Œæ•´çš„æ™‚åˆ†æ ¼å¼ï¼‰
    elif "é»" in text or ":" in text:
        # æå–æ™‚é–“
        time_match = re.search(r'(\d{1,2})[é»:]?(\d{0,2})', converted_text)
        if time_match:
            hour = int(time_match.group(1))
            minute = int(time_match.group(2)) if time_match.group(2) else 0

            # æª¢æŸ¥æ˜¯å¦æ˜ç¢ºæåˆ°"æ˜å¤©"
            if "æ˜å¤©" in text:
                # å¦‚æœæ˜å¤©ä¹Ÿæœ‰ä¸‹åˆï¼Œéœ€è¦è½‰æ›æ™‚é–“
                if "ä¸‹åˆ" in text and hour <= 12:
                    if hour == 12:
                        # ä¸‹åˆ12é»å°±æ˜¯ä¸­åˆ12é»ï¼Œä¿æŒ12
                        pass
                    elif hour < 12:
                        # ä¸‹åˆ3é» = 15é»
                        hour += 12
                # å¦‚æœæ˜å¤©ä¹Ÿæœ‰æ™šä¸Šï¼Œéœ€è¦è½‰æ›æ™‚é–“
                elif "æ™šä¸Š" in text and hour <= 12:
                    if hour == 12:
                        # æ™šä¸Š12é»å°±æ˜¯åˆå¤œï¼Œå³0é»
                        hour = 0
                    elif hour < 12:
                        # æ™šä¸Š7é» = 19é»
                        hour += 12
                tomorrow = now + timedelta(days=1)
                target_time = tomorrow.replace(hour=hour, minute=minute, second=0, microsecond=0)
                return target_time.strftime("%Y-%m-%d %H:%M")

            # å¦‚æœæ˜ç¢ºæåˆ°"ä¸‹åˆ"ä¸”å°æ™‚æ•¸ <= 12ï¼Œç›´æ¥è½‰ç‚º24å°æ™‚åˆ¶
            if "ä¸‹åˆ" in text and hour <= 12:
                if hour == 12:
                    # ä¸‹åˆ12é»å°±æ˜¯ä¸­åˆ12é»ï¼Œä¿æŒ12
                    pass
                elif hour < 12:
                    # ä¸‹åˆ3é» = 15é»
                    hour += 12
                target_time = now.replace(hour=hour, minute=minute, second=0, microsecond=0)
                return target_time.strftime("%Y-%m-%d %H:%M")

            # å¦‚æœæ˜ç¢ºæåˆ°"æ™šä¸Š"ä¸”å°æ™‚æ•¸ <= 12ï¼Œç›´æ¥è½‰ç‚º24å°æ™‚åˆ¶
            if "æ™šä¸Š" in text and hour <= 12:
                if hour == 12:
                    # æ™šä¸Š12é»å°±æ˜¯åˆå¤œï¼Œå³0é»
                    hour = 0
                elif hour < 12:
                    # æ™šä¸Š7é» = 19é»
                    hour += 12
                # æ™šä¸Šæ™‚é–“ç›´æ¥è¿”å›ï¼Œä¸é€²è¡Œé€²ä¸€æ­¥è™•ç†
                target_time = now.replace(hour=hour, minute=minute, second=0, microsecond=0)
                return target_time.strftime("%Y-%m-%d %H:%M")

            target_time = now.replace(hour=hour, minute=minute, second=0, microsecond=0)

            # å¦‚æœæ²’æœ‰æ˜ç¢ºæåˆ°"æ™šä¸Š"ï¼Œæ™ºèƒ½è™•ç†12å°æ™‚åˆ¶
            if target_time <= now and hour <= 12:
                # æª¢æŸ¥æ˜¯å¦ç‚ºæ™šä¸Šæ™‚é–“ï¼ˆåŠ 12å°æ™‚ï¼‰
                if hour < 12:  # é¿å…12é»é‡è¤‡åŠ 12
                    evening_time = now.replace(hour=hour + 12, minute=minute, second=0, microsecond=0)
                    if evening_time > now:
                        return evening_time.strftime("%Y-%m-%d %H:%M")

                # å¦‚æœæ™šä¸Šæ™‚é–“ä¹Ÿéäº†ï¼Œæˆ–è€…æ˜¯12é»ï¼Œè¨­ç‚ºæ˜å¤©
                target_time += timedelta(days=1)

            return target_time.strftime("%Y-%m-%d %H:%M")

    return None

# â”€â”€â”€â”€â”€â”€â”€ æé†’ç³»çµ± â”€â”€â”€â”€â”€â”€â”€
reminder_scheduler = None
reminder_thread = None

def start_reminder_system():
    """å•Ÿå‹•æé†’ç³»çµ±å¾Œå°æœå‹™"""
    global reminder_scheduler, reminder_thread
    
    if reminder_thread and reminder_thread.is_alive():
        return  # å·²ç¶“åœ¨é‹è¡Œ
    
    def run_scheduler():
        global reminder_scheduler
        reminder_scheduler = schedule
        
        # æ¯åˆ†é˜æª¢æŸ¥ä¸€æ¬¡æ˜¯å¦æœ‰æé†’
        reminder_scheduler.every().minute.do(check_reminders)
        
        while True:
            reminder_scheduler.run_pending()
            time.sleep(30)  # æ¯30ç§’æª¢æŸ¥ä¸€æ¬¡
    
    reminder_thread = threading.Thread(target=run_scheduler, daemon=True)
    reminder_thread.start()
    print("æé†’ç³»çµ±å·²å•Ÿå‹•ï¼ˆå¾Œå°é‹è¡Œï¼‰")

def check_reminders():
    """æª¢æŸ¥ä¸¦åŸ·è¡Œåˆ°æ™‚çš„æé†’"""
    try:
        schedules = load_json(SCHEDULE_FILE)
        current_time = datetime.now()
        
        for i, schedule_item in enumerate(schedules):
            if 'time' in schedule_item and 'reminded' not in schedule_item:
                # æª¢æŸ¥ time æ˜¯å¦ç‚º None æˆ–ç©ºå€¼
                if schedule_item['time'] is None or schedule_item['time'] == "":
                    continue  # è·³éæ²’æœ‰æ™‚é–“çš„æé†’
                
                try:
                    schedule_time = datetime.strptime(schedule_item['time'], "%Y-%m-%d %H:%M")
                    # æª¢æŸ¥æ˜¯å¦åˆ°äº†æé†’æ™‚é–“ï¼ˆå…è¨±1åˆ†é˜èª¤å·®ï¼‰
                    time_diff = abs((current_time - schedule_time).total_seconds())
                    
                    if time_diff <= 60:  # 1åˆ†é˜å…§
                        # åŸ·è¡Œæé†’
                        execute_reminder(schedule_item)
                        # æ¨™è¨˜ç‚ºå·²æé†’
                        schedules[i]['reminded'] = True
                        save_json(SCHEDULE_FILE, schedules)
                        
                except ValueError:
                    continue  # æ™‚é–“æ ¼å¼éŒ¯èª¤ï¼Œè·³é
                    
    except Exception as e:
        print(f"æª¢æŸ¥æé†’æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

def execute_reminder(schedule_item):
    """åŸ·è¡Œæé†’å‹•ä½œ"""
    task = schedule_item.get('task', 'æœªçŸ¥ä»»å‹™')
    person = schedule_item.get('person', 'ä½ ')
    
    # è·¨å¹³å°ç³»çµ±æç¤ºéŸ³
    play_system_beep()
    
    # æ ¹æ“šä»»å‹™é¡å‹ç”Ÿæˆåˆé©çš„æé†’æ–‡å­—
    if "åƒè—¥" in task:
        reminder_text = f"æé†’ï¼š{person}ï¼Œè¨˜å¾—åƒè—¥å–”ï¼"
    elif "ç¡è¦º" in task:
        reminder_text = f"æé†’ï¼š{person}ï¼Œè©²ç¡è¦ºäº†ï¼"
    elif "èµ·åºŠ" in task:
        reminder_text = f"æé†’ï¼š{person}ï¼Œè©²èµ·åºŠäº†ï¼"
    elif "åƒé£¯" in task:
        reminder_text = f"æé†’ï¼š{person}ï¼Œè©²åƒé£¯äº†ï¼"
    elif "é–‹æœƒ" in task or "æœƒè­°" in task:
        reminder_text = f"æé†’ï¼š{person}ï¼Œæœƒè­°æ™‚é–“åˆ°äº†ï¼"
    elif "æé†’" in task:
        # å¦‚æœä»»å‹™å°±æ˜¯"æé†’"ï¼Œå˜—è©¦å¾åŸå§‹æ–‡å­—ä¸­æå–æ›´å…·é«”çš„å…§å®¹
        reminder_text = f"æé†’ï¼š{person}ï¼Œæ‚¨è¨­å®šçš„æ™‚é–“åˆ°äº†ï¼"
    else:
        reminder_text = f"æé†’ï¼š{person}ï¼Œè©²{task}äº†ï¼"
    
    print(f"\n{reminder_text}")
    
    # èªéŸ³æé†’ï¼ˆç•°æ­¥åŸ·è¡Œï¼‰
    asyncio.run(play_reminder_voice(reminder_text))

def play_system_beep():
    """è·¨å¹³å°ç³»çµ±æç¤ºéŸ³"""
    try:
        if platform.system() == "Windows" and winsound:
            winsound.MessageBeep(winsound.MB_ICONEXCLAMATION)
        elif platform.system() == "Linux":
            # Linux ä½¿ç”¨ ALSA æˆ– PulseAudio
            os.system("paplay /usr/share/sounds/alsa/Front_Left.wav 2>/dev/null || echo -e '\\a'")
        elif platform.system() == "Darwin":  # macOS
            os.system("afplay /System/Library/Sounds/Glass.aiff 2>/dev/null || echo -e '\\a'")
        else:
            # é€šç”¨æ–¹æ¡ˆï¼šçµ‚ç«¯éŸ¿éˆ´
            print("\a", end="")
    except Exception as e:
        print(f"ç³»çµ±æç¤ºéŸ³æ’­æ”¾å¤±æ•—ï¼š{e}")
        # æœ€å¾Œå‚™ç”¨æ–¹æ¡ˆï¼šçµ‚ç«¯éŸ¿éˆ´
        print("\a", end="")

async def play_reminder_voice(text):
    """æ’­æ”¾æé†’èªéŸ³"""
    # æ¸…ç†æ–‡å­—ä»¥ä¾›èªéŸ³åˆæˆ
    clean_speech_text = clean_text_for_speech(text)
    
    try:
        # å…ˆå˜—è©¦ä½¿ç”¨ Edge-TTS
        import asyncio
        # è¨­å®šè¼ƒçŸ­çš„è¶…æ™‚æ™‚é–“ï¼Œé¿å…é•·æ™‚é–“ç­‰å¾…
        tts = edge_tts.Communicate(clean_speech_text, TTS_VOICE)
        # ä½¿ç”¨ asyncio.wait_for è¨­å®š 10 ç§’è¶…æ™‚
        await asyncio.wait_for(tts.save("reminder_audio.mp3"), timeout=10.0)
        
        # è·¨å¹³å°éŸ³é »æ’­æ”¾
        play_audio_file("reminder_audio.mp3")
        print("Edge-TTS æé†’èªéŸ³æ’­æ”¾æˆåŠŸ")
        
    except (Exception, asyncio.TimeoutError) as e:
        print(f"Edge-TTS æé†’å¤±æ•—ï¼ˆç¶²è·¯å•é¡Œæˆ–æœå‹™ä¸å¯ç”¨ï¼‰ï¼š{e}")
        
        # å‚™ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨ç³»çµ±èªéŸ³åˆæˆ
        try:
            play_system_voice(clean_speech_text)
            print("ä½¿ç”¨ç³»çµ±èªéŸ³æ’­æ”¾æé†’")
        except Exception as backup_error:
            print(f"ç³»çµ±èªéŸ³ä¹Ÿå¤±æ•—ï¼š{backup_error}")
            # æœ€å¾Œå‚™ç”¨æ–¹æ¡ˆï¼šå¤šé‡æç¤ºéŸ³
            for _ in range(3):
                play_system_beep()
                await asyncio.sleep(0.5)
            print("èªéŸ³æé†’å¤±æ•—ï¼Œä½¿ç”¨å¤šé‡æç¤ºéŸ³")

def play_audio_file(filename):
    """è·¨å¹³å°éŸ³é »æª”æ¡ˆæ’­æ”¾"""
    try:
        if platform.system() == "Windows":
            os.system(f"start {filename}")
        elif platform.system() == "Linux":
            # Linux ä½¿ç”¨å¤šç¨®æ’­æ”¾å™¨å˜—è©¦
            players = ["mpg123", "ffplay", "aplay", "paplay"]
            for player in players:
                if os.system(f"which {player} >/dev/null 2>&1") == 0:
                    os.system(f"{player} {filename} >/dev/null 2>&1 &")
                    break
            else:
                print("æœªæ‰¾åˆ°éŸ³é »æ’­æ”¾å™¨ï¼Œè«‹å®‰è£ mpg123 æˆ– ffmpeg")
        elif platform.system() == "Darwin":  # macOS
            os.system(f"afplay {filename}")
    except Exception as e:
        print(f"éŸ³é »æ’­æ”¾å¤±æ•—ï¼š{e}")

def play_system_voice(text):
    """è·¨å¹³å°ç³»çµ±èªéŸ³åˆæˆ"""
    try:
        if platform.system() == "Windows":
            # Windows SAPI
            try:
                import pyttsx3
                engine = pyttsx3.init()
                engine.setProperty('rate', 150)
                engine.setProperty('volume', 0.9)
                # å˜—è©¦è¨­å®šä¸­æ–‡èªéŸ³
                voices = engine.getProperty('voices')
                for voice in voices:
                    if 'chinese' in voice.name.lower() or 'zh' in voice.id.lower() or 'mandarin' in voice.name.lower():
                        engine.setProperty('voice', voice.id)
                        break
                engine.say(text)
                engine.runAndWait()
            except ImportError:
                print("pyttsx3 æœªå®‰è£ï¼Œç„¡æ³•ä½¿ç”¨ Windows èªéŸ³")
                raise
                
        elif platform.system() == "Linux":
            # Linux ä½¿ç”¨ espeak æˆ– festival
            if os.system("which espeak >/dev/null 2>&1") == 0:
                os.system(f"espeak -v zh '{text}' 2>/dev/null || espeak '{text}' 2>/dev/null")
            elif os.system("which festival >/dev/null 2>&1") == 0:
                os.system(f"echo '{text}' | festival --tts 2>/dev/null")
            else:
                print("æœªæ‰¾åˆ°èªéŸ³åˆæˆå·¥å…·ï¼Œè«‹å®‰è£ espeak æˆ– festival")
                raise Exception("No TTS engine found")
                
        elif platform.system() == "Darwin":  # macOS
            os.system(f"say '{text}'")
            
    except Exception as e:
        print(f"ç³»çµ±èªéŸ³åˆæˆå¤±æ•—ï¼š{e}")
        raise

# â”€â”€â”€â”€â”€â”€â”€ æ’­æ”¾èªéŸ³åŠŸèƒ½ â”€â”€â”€â”€â”€â”€â”€
async def play_response(response_text):
    global is_playing_audio
    
    with audio_lock:
        is_playing_audio = True
    
    try:
        # æ¸…ç†æ–‡å­—ä»¥ä¾›èªéŸ³åˆæˆ
        clean_speech_text = clean_text_for_speech(response_text)
        
        try:
            # å…ˆå˜—è©¦ä½¿ç”¨ Edge-TTS
            import asyncio
            tts = edge_tts.Communicate(clean_speech_text, TTS_VOICE)
            # è¨­å®š 10 ç§’è¶…æ™‚
            await asyncio.wait_for(tts.save("response_audio.mp3"), timeout=10.0)
            
            # ä½¿ç”¨æ›´ç²¾ç¢ºçš„æ’­æ”¾æ™‚é–“ä¼°ç®—
            estimated_duration = len(clean_speech_text) * 0.18 + 1.0  # æ¯å€‹å­—ç´„0.18ç§’ + 1ç§’ç·©è¡
            print(f"Edge-TTS èªéŸ³åˆæˆå®Œæˆï¼Œé ä¼°æ’­æ”¾æ™‚é–“ï¼š{estimated_duration:.1f}ç§’")
            
            # è·¨å¹³å°éŸ³é »æ’­æ”¾
            play_audio_file("response_audio.mp3")
            print("Edge-TTS èªéŸ³æ’­æ”¾é–‹å§‹")
            
            # ç­‰å¾…èªéŸ³æ’­æ”¾å®Œæˆï¼ˆä½¿ç”¨æ›´ä¿å®ˆçš„æ™‚é–“ä¼°ç®—ï¼‰
            await asyncio.sleep(max(3.0, estimated_duration))  # è‡³å°‘ç­‰å¾…3ç§’
            print("Edge-TTS æ’­æ”¾æ™‚é–“çµæŸ")
            
        except (Exception, asyncio.TimeoutError) as e:
            print(f"Edge-TTS å¤±æ•—ï¼ˆç¶²è·¯å•é¡Œæˆ–æœå‹™ä¸å¯ç”¨ï¼‰ï¼š{e}")
            # å‚™ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨ç³»çµ±èªéŸ³åˆæˆ
            try:
                play_system_voice(clean_speech_text)
                print("ä½¿ç”¨ç³»çµ±èªéŸ³æ’­æ”¾å®Œæˆ")
                
                # é¡å¤–ç­‰å¾…ç¢ºä¿æ’­æ”¾å®Œæˆ
                await asyncio.sleep(1.5)
                
            except Exception as backup_error:
                print(f"ç³»çµ±èªéŸ³ä¹Ÿå¤±æ•—ï¼š{backup_error}")
                print("åªé¡¯ç¤ºæ–‡å­—å›æ‡‰ï¼Œç„¡èªéŸ³æ’­æ”¾")
                await asyncio.sleep(0.5)  # çŸ­æš«ç­‰å¾…å¾Œé‡‹æ”¾é–
                
    finally:
        # é‡‹æ”¾æ’­æ”¾ç‹€æ…‹ä¸¦ç­‰å¾…é¡å¤–æ™‚é–“é¿å…éŒ„éŸ³ç«‹å³é–‹å§‹
        await asyncio.sleep(2.0)  # å¢åŠ åˆ°2ç§’é¿å…éŸ³é »é‡ç–Š
        with audio_lock:
            is_playing_audio = False
        print("ğŸµ èªéŸ³æ’­æ”¾å®Œæˆï¼Œç­‰å¾…2ç§’å¾Œæº–å‚™æ¥å—æ–°çš„èªéŸ³è¼¸å…¥...")
        
        # é¡å¤–ç­‰å¾…ï¼Œç¢ºä¿éŸ³é »ç³»çµ±å®Œå…¨é‡‹æ”¾
        await asyncio.sleep(1.0)

# â”€â”€â”€â”€â”€â”€â”€ STT éŒ„éŸ³èˆ‡è¾¨è­˜ â”€â”€â”€â”€â”€â”€â”€
def record_audio(duration=None, samplerate=None):
    """å›ºå®šæ™‚é–“éŒ„éŸ³å‡½æ•¸ï¼Œæ”¯æ´æŒ‰ Enter æå‰åœæ­¢ï¼Œæœƒæª¢æŸ¥æ˜¯å¦æ­£åœ¨æ’­æ”¾èªéŸ³ä»¥é¿å…è¡çª"""
    global is_playing_audio
    
    # ä½¿ç”¨ç’°å¢ƒè®Šæ•¸é…ç½®æˆ–é è¨­å€¼
    if duration is None:
        duration = AUDIO_DURATION
    if samplerate is None:
        samplerate = AUDIO_SAMPLE_RATE
    
    # ç­‰å¾…èªéŸ³æ’­æ”¾å®Œæˆ
    wait_count = 0
    while is_playing_audio:
        wait_count += 1
        if wait_count == 1:
            print("â¸ ç­‰å¾…èªéŸ³æ’­æ”¾å®Œæˆ...")
        elif wait_count % 4 == 0:  # æ¯2ç§’æç¤ºä¸€æ¬¡
            print("â¸ ä»åœ¨ç­‰å¾…èªéŸ³æ’­æ”¾å®Œæˆ...")
        time.sleep(0.5)
    
    # é¡å¤–ç­‰å¾…ç¢ºä¿éŸ³é »ç³»çµ±é‡‹æ”¾
    if wait_count > 0:
        print("ğŸµ èªéŸ³æ’­æ”¾å®Œæˆï¼Œé¡å¤–ç­‰å¾…1ç§’ç¢ºä¿éŸ³é »ç³»çµ±é‡‹æ”¾...")
        time.sleep(1.0)
    
    print(f"\né–‹å§‹éŒ„éŸ³ï¼ˆæœ€é•· {duration} ç§’ï¼‰")
    print("ğŸ’¡ æç¤ºï¼šèªªå®Œè©±å¾ŒæŒ‰ Enter å¯æå‰çµæŸéŒ„éŸ³")
    
    # ç”¨æ–¼æ§åˆ¶éŒ„éŸ³æ˜¯å¦æå‰çµæŸ
    stop_recording = threading.Event()
    
    def wait_for_enter():
        """ç­‰å¾…ç”¨æˆ¶æŒ‰ Enter éµ"""
        try:
            input()  # ç­‰å¾…ç”¨æˆ¶æŒ‰ Enter
            stop_recording.set()
        except:
            pass
    
    try:
        # é–‹å§‹éŒ„éŸ³
        recording = sd.rec(int(duration * samplerate), samplerate=samplerate, channels=1, dtype='int16')
        
        # å•Ÿå‹•æŒ‰éµæª¢æ¸¬ç·šç¨‹
        enter_thread = threading.Thread(target=wait_for_enter, daemon=True)
        enter_thread.start()
        
        # é¡¯ç¤ºå€’æ•¸é€²åº¦ï¼ŒåŒæ™‚æª¢æŸ¥æ˜¯å¦æŒ‰äº† Enter
        for i in range(duration):
            if stop_recording.is_set():
                # ç”¨æˆ¶æŒ‰äº† Enterï¼Œæå‰åœæ­¢éŒ„éŸ³
                actual_duration = i + 1
                print(f"\nç”¨æˆ¶æŒ‰ Enter æå‰çµæŸï¼Œå…±éŒ„éŸ³ {actual_duration} ç§’")
                sd.stop()
                
                # æˆªå–å¯¦éš›éŒ„éŸ³é•·åº¦
                actual_samples = int(actual_duration * samplerate)
                recording = recording[:actual_samples]
                break
            
            remaining = duration - i
            print(f"éŒ„éŸ³ä¸­... å‰©é¤˜ {remaining} ç§’ (æŒ‰ Enter æå‰çµæŸ)", end='\r')
            time.sleep(1)
        else:
            # æ­£å¸¸çµæŸéŒ„éŸ³
            print(f"\né”åˆ°æœ€å¤§éŒ„éŸ³æ™‚é–“ {duration} ç§’")
            sd.wait()  # ç­‰å¾…éŒ„éŸ³å®Œæˆ
        
        # ä¿å­˜éŒ„éŸ³æª”æ¡ˆ
        write(AUDIO_PATH, samplerate, recording)
        print("éŒ„éŸ³å®Œæˆä¸¦å·²ä¿å­˜")
        
    except KeyboardInterrupt:
        print("\nç”¨æˆ¶æ‰‹å‹•åœæ­¢éŒ„éŸ³")
        sd.stop()
        return False
    except Exception as e:
        print(f"\néŒ„éŸ³éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        sd.stop()
        return False
    
    return True

def transcribe_audio():
    try:
        print(" èªéŸ³è¾¨è­˜ä¸­...")
        result = whisper_model.transcribe(AUDIO_PATH, language="zh")
        raw_text = result["text"].strip()
        print(f"åŸå§‹è¾¨è­˜çµæœï¼šã€Œ{raw_text}ã€")
        
        cleaned_text = clean_text_from_stt(raw_text)
        print(f"æ¸…ç†å¾Œçµæœï¼šã€Œ{cleaned_text}ã€")
        print(f"è©èªæ•¸é‡ï¼š{len(cleaned_text.split()) if cleaned_text else 0}")
        
        # é™ä½æª¢æ¸¬é–€æª»ï¼šåªè¦æœ‰ä»»ä½•æ–‡å­—å°±ç®—æœ‰æ•ˆ
        if not cleaned_text or len(cleaned_text.strip()) < 2:
            print(" æœªåµæ¸¬åˆ°æœ‰æ•ˆèªéŸ³ï¼Œé€²å…¥å¾…æ©Ÿç‹€æ…‹...")
            return None
            
        # ç°¡åŒ–é‡è¤‡æª¢æ¸¬
        words = cleaned_text.split()
        if len(words) > 0:
            word_counts = {word: words.count(word) for word in words}
            max_repeat = max(word_counts.values()) if word_counts else 0
            if len(words) > 1 and max_repeat > len(words) * 0.7:
                print("èªéŸ³å…§å®¹é‡è¤‡ï¼Œé€²å…¥å¾…æ©Ÿç‹€æ…‹...")
                return None
                
        print(f" æœ‰æ•ˆèªéŸ³ï¼šã€Œ{cleaned_text}ã€")
        return cleaned_text
    except FileNotFoundError:
        print(f" æ‰¾ä¸åˆ°éŸ³æª”ï¼š{AUDIO_PATH}")
=======
    print(f"å·²è¨˜éŒ„ï¼š{data['owner']}çš„ã€Œ{data['item']}ã€æ”¾åœ¨ {data['location']}")

def parse_relative_time(text):
    # é€™å€‹å‡½å¼è² è²¬è§£æç›¸å°æ™‚é–“ï¼Œä¾‹å¦‚ã€Œæ˜å¤©ã€ã€ã€Œå¾Œå¤©ã€ç­‰ï¼Œä¸¦å›å‚³å°æ‡‰çš„çµ•å°æ™‚é–“å­—ä¸²
    # å¯¦ä½œç´°ç¯€çœç•¥
    pass

# â”€â”€â”€â”€â”€â”€â”€ æ’­æ”¾èªéŸ³åŠŸèƒ½ â”€â”€â”€â”€â”€â”€â”€
async def play_response(response_text):
    try:
        tts = edge_tts.Communicate(response_text, "zh-CN-XiaoxiaoNeural")
        await tts.save("response_audio.mp3")
        import os
        os.system("start response_audio.mp3")
    except Exception as e:
        print(f"èªéŸ³æ’­æ”¾å¤±æ•—ï¼š{e}")

# â”€â”€â”€â”€â”€â”€â”€ STT éŒ„éŸ³èˆ‡è¾¨è­˜ â”€â”€â”€â”€â”€â”€â”€
def record_audio(duration=5, samplerate=16000):
    print(f"\né–‹å§‹éŒ„éŸ³ {duration} ç§’ï¼Œè«‹èªªè©±...")
    recording = sd.rec(int(duration * samplerate), samplerate=samplerate, channels=1, dtype='int16')
    sd.wait()
    write(AUDIO_PATH, samplerate, recording)
    print("éŒ„éŸ³å®Œæˆ")

def transcribe_audio():
    try:
        print("èªéŸ³è¾¨è­˜ä¸­...")
        result = whisper_model.transcribe(AUDIO_PATH, language="zh")
        raw_text = result["text"].strip()
        cleaned_text = clean_text_from_stt(raw_text)
        if not cleaned_text or len(cleaned_text.split()) < 3:
            print("æœªåµæ¸¬åˆ°æœ‰æ•ˆèªéŸ³ï¼Œé€²å…¥å¾…æ©Ÿç‹€æ…‹...")
            return None
        word_counts = {word: cleaned_text.split().count(word) for word in cleaned_text.split()}
        if max(word_counts.values()) > len(cleaned_text.split()) * 0.6:
            print("èªéŸ³å…§å®¹é‡è¤‡ï¼Œé€²å…¥å¾…æ©Ÿç‹€æ…‹...")
            return None
        return cleaned_text
    except FileNotFoundError:
        print(f"æ‰¾ä¸åˆ°éŸ³æª”ï¼š{AUDIO_PATH}")
>>>>>>> cdde5e3fc6d7bae51be920ccbd20fd218dfdeea1
        return None
    except Exception as e:
        print(f"èªéŸ³è¾¨è­˜å¤±æ•—ï¼š{e}")
        return None

# â”€â”€â”€â”€â”€â”€â”€ èŠå¤©èˆ‡æƒ…ç·’è¾¨è­˜åŠŸèƒ½ â”€â”€â”€â”€â”€â”€â”€
<<<<<<< HEAD
async def chat_with_emotion(text, audio_path, query_context=None, enable_facial=None):
    """
    å¤šæ¨¡æ…‹æƒ…ç·’æ„ŸçŸ¥å°è©±ç³»çµ±
    
    Args:
        text: ä½¿ç”¨è€…è¼¸å…¥æ–‡å­—
        audio_path: èªéŸ³æª”æ¡ˆè·¯å¾‘
        query_context: æŸ¥è©¢ä¸Šä¸‹æ–‡
        enable_facial: æ˜¯å¦å•Ÿç”¨è‡‰éƒ¨è¾¨è­˜ï¼ˆNone=è‡ªå‹•æ±ºå®šï¼‰
    """
    # æ ¹æ“šé…ç½®æ±ºå®šæ˜¯å¦å•Ÿç”¨è‡‰éƒ¨è¾¨è­˜
    if enable_facial is None:
        enable_facial = not CURRENT_MODE["facial_simulation"]  # ç”Ÿç”¢æ¨¡å¼å•Ÿç”¨è‡‰éƒ¨è¾¨è­˜
    
    # ä½¿ç”¨å¤šæ¨¡æ…‹æƒ…ç·’è¾¨è­˜
    if CURRENT_MODE["debug_output"]:
        print(f"ğŸ­ å•Ÿå‹•å¤šæ¨¡æ…‹æƒ…ç·’åˆ†æ (è‡‰éƒ¨è¾¨è­˜: {'å•Ÿç”¨' if enable_facial else 'åœç”¨'})")
    
    final_emotion, emotion_details = multi_modal_emotion_detection(
        text=text,
        audio_path=audio_path if audio_path and audio_path != "test_audio.wav" else None,
        enable_facial=enable_facial
    )
    
    # æå–å„æ¨¡æ…‹æƒ…ç·’ï¼ˆå‘å¾Œç›¸å®¹ï¼‰
    text_emotion = emotion_details.get("text_emotion", final_emotion)
    audio_emotion = emotion_details.get("audio_emotion", final_emotion)
    facial_emotion = emotion_details.get("facial_emotion", None)

    history = load_json(CHAT_HISTORY_FILE)[-3:]
    context = "\n".join([f"ä½¿ç”¨è€…ï¼š{h['user']}\nAIï¼š{h['response']}" for h in history])

    # æ ¹æ“šæœ€çµ‚èåˆæƒ…ç·’é¸æ“‡èªæ°£
=======
async def chat_with_emotion(text, audio_path):

    # ====== å–å¾—ä¸‰æ¨¡æ…‹æƒ…ç·’ï¼ˆæ–‡å­—ã€èªéŸ³ã€è‡‰éƒ¨ï¼‰ä¸¦è¨˜éŒ„ ======
    # 1. å–å¾—æ–‡å­—æƒ…ç·’
    text_emotion = detect_text_emotion(text)
    # 2. å–å¾—èªéŸ³æƒ…ç·’
    audio_emotion = detect_audio_emotion(audio_path)
    # 3. å–å¾—è‡‰éƒ¨æƒ…ç·’ï¼ˆå‡è¨­åœ–ç‰‡è·¯å¾‘ç‚º face_input.jpgï¼‰
    facial_emotion = None
    try:
        from emotion_module import detect_facial_emotion, fuse_emotions
        facial_emotion, _ = detect_facial_emotion("face_input.jpg")
        # 4. èåˆä¸‰æ¨¡æ…‹æƒ…ç·’ä¸¦è‡ªå‹•è¨˜éŒ„
        final_emotion, _ = fuse_emotions(text_emotion, audio_emotion, facial_emotion=facial_emotion)
    except Exception as e:
        print(f"[è­¦å‘Š] è¨˜éŒ„å¤šæ¨¡æ…‹æƒ…ç·’å¤±æ•—ï¼š{e}")
    # =========================================================

    # 5. å–å¾—æœ€è¿‘ä¸‰å‰‡å°è©±ç´€éŒ„ï¼Œä½œç‚ºä¸Šä¸‹æ–‡
    history = load_json(CHAT_HISTORY_FILE)[-3:]
    context = "\n".join([f"ä½¿ç”¨è€…ï¼š{h['user']}\nAIï¼š{h['response']}" for h in history])

    # 6. æ ¹æ“šæ–‡å­—æƒ…ç·’æ±ºå®šèªæ°£
>>>>>>> cdde5e3fc6d7bae51be920ccbd20fd218dfdeea1
    tone_map = {
        "å¿«æ¨‚": "ç”¨é–‹æœ—æ´»æ½‘çš„èªæ°£",
        "æ‚²å‚·": "ç”¨æº«æŸ”å®‰æ…°çš„èªæ°£",
        "ç”Ÿæ°£": "ç”¨ç©©å®šç†æ€§çš„èªæ°£",
        "ä¸­æ€§": "è‡ªç„¶åœ°"
    }
<<<<<<< HEAD
    tone = tone_map.get(final_emotion, "è‡ªç„¶åœ°")

    # å¦‚æœæœ‰æŸ¥è©¢ä¸Šä¸‹æ–‡ï¼ŒåŠ å…¥åˆ° prompt ä¸­
    context_info = ""
    if query_context:
        context_info = f"\næŸ¥è©¢çµæœï¼š{query_context}\nè«‹æ ¹æ“šé€™å€‹æŸ¥è©¢çµæœä¾†å›æ‡‰ä½¿ç”¨è€…ã€‚"

    # ç²å–ç•¶å‰æ™‚é–“è³‡è¨Šï¼ˆåªåœ¨éœ€è¦æ™‚ä½¿ç”¨ï¼‰
    now = datetime.now()
    
    # æª¢æŸ¥æ˜¯å¦ç‚ºæ™‚é–“ç›¸é—œæŸ¥è©¢
    is_time_query = detect_time_query(text)
    current_time_info = ""
    if is_time_query:
        current_time_info = f"\nç•¶å‰æ™‚é–“è³‡è¨Šï¼š\n- æ—¥æœŸï¼š{now.strftime('%Yå¹´%mæœˆ%dæ—¥')}\n- æ™‚é–“ï¼š{now.strftime('%H:%M')}\n- æ˜ŸæœŸï¼š{['ä¸€', 'äºŒ', 'ä¸‰', 'å››', 'äº”', 'å…­', 'æ—¥'][now.weekday()]}\n"

    # åŠ å…¥æƒ…ç·’æ„ŸçŸ¥æç¤º
    emotion_context = ""
    if len(emotion_details["modalities_used"]) > 1:
        emotion_context = f"\næƒ…ç·’æ„ŸçŸ¥ï¼šé€é{'+'.join(emotion_details['modalities_used'])}åˆ†æï¼Œä½¿ç”¨è€…æƒ…ç·’åå‘ã€Œ{final_emotion}ã€ï¼Œè«‹ç›¸æ‡‰èª¿æ•´å›æ‡‰èªæ°£ã€‚"

    prompt = f"""{context}{context_info}{current_time_info}{emotion_context}
ä½¿ç”¨è€…ï¼š{text}
ä½ æ˜¯ä¸€å€‹è¦ªåˆ‡è‡ªç„¶ã€æœƒèªªå£èªä¸­æ–‡çš„æœ‹å‹å‹æ©Ÿå™¨äººï¼Œè«‹æ ¹æ“šä¸Šé¢çš„å°è©±èˆ‡èªæ°£ï¼Œçµ¦å‡ºä¸€æ®µè‡ªç„¶çš„ä¸­æ–‡å›æ‡‰ã€‚
è«‹é¿å…åˆ—é»ã€æ ¼å¼åŒ–ã€éæ–¼æ­£å¼çš„ç”¨è©ï¼Œä¸è¦æ•™å­¸èªæ°£ï¼Œä¹Ÿä¸è¦å•å¤ªå¤šå•é¡Œï¼Œåªéœ€å›ä¸€å¥è‡ªç„¶çš„å›ç­”å³å¯ã€‚
ä¸è¦ä¸»å‹•æ‰¿è«¾æˆ–åŸ·è¡Œç¾å¯¦ä¸­ä½ ç„¡æ³•åšåˆ°çš„è¡Œå‹•ï¼ˆä¾‹å¦‚ï¼šæº–å‚™ææ–™ã€å¹«å¿™æ‹¿æ±è¥¿ã€å¯¦éš›å»åšæŸäº‹ï¼‰ï¼Œåªèƒ½çµ¦äºˆé™ªä¼´ã€æé†’ã€èŠå¤©æˆ–æƒ…ç·’æ”¯æŒã€‚
{"å¦‚æœä½¿ç”¨è€…è©¢å•æ™‚é–“ï¼Œè«‹ä½¿ç”¨ä¸Šé¢æä¾›çš„ç•¶å‰æ™‚é–“è³‡è¨Šæº–ç¢ºå›ç­”ã€‚" if is_time_query else ""}
è«‹ä»¥{tone}èªæ°£å›æ‡‰ï¼Œç›´æ¥èªªä¸­æ–‡ï¼š"""

    reply = safe_generate(prompt)
    save_chat_log(text, reply)
    
    # ä¿å­˜è©³ç´°æƒ…ç·’è¨˜éŒ„
    emotion_log = {
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "user_text": text,  # æ·»åŠ ç”¨æˆ¶åŸå§‹æ–‡å­—å…§å®¹
        "text_emotion": text_emotion,
        "audio_emotion": audio_emotion,
        "facial_emotion": facial_emotion,
        "final_emotion": final_emotion,
        "modalities": emotion_details["modalities_used"],
        "confidence": emotion_details.get("confidence_scores", {})
    }
    save_emotion_log_enhanced(emotion_log)
    
    # è¨˜éŒ„æƒ…ç·’åˆ°çµ±è¨ˆç³»çµ±ï¼ˆä½¿ç”¨æœ€çµ‚èåˆæƒ…ç·’ï¼‰
    record_daily_emotion(final_emotion)

    await play_response(reply)

    return {
        "reply": reply,
        "text_emotion": text_emotion,
        "audio_emotion": audio_emotion,
        "facial_emotion": facial_emotion,
        "final_emotion": final_emotion,
        "emotion_details": emotion_details
    }

def save_emotion_log_enhanced(emotion_log):
    """å„²å­˜å¢å¼·çš„æƒ…ç·’è¨˜éŒ„"""
    try:
        with open(EMOTION_LOG_FILE, "r", encoding="utf-8") as f:
            records = json.load(f)
    except:
        records = []
    
    records.append(emotion_log)
    
    # ä¿ç•™æœ€è¿‘ 1000 ç­†è¨˜éŒ„
    if len(records) > 1000:
        records = records[-1000:]
    
    with open(EMOTION_LOG_FILE, "w", encoding="utf-8") as f:
        json.dump(records, f, ensure_ascii=False, indent=2)

=======
    tone = tone_map.get(text_emotion, "è‡ªç„¶åœ°")

    # 7. çµ„åˆ promptï¼Œè«‹ Gemini ç”¢ç”Ÿå›æ‡‰
    prompt = f"""{context}
ä½¿ç”¨è€…ï¼š{text}
ä½ æ˜¯ä¸€å€‹è¦ªåˆ‡è‡ªç„¶ã€æœƒèªªå£èªä¸­æ–‡çš„æœ‹å‹å‹æ©Ÿå™¨äººï¼Œè«‹æ ¹æ“šä¸Šé¢çš„å°è©±èˆ‡èªæ°£ï¼Œçµ¦å‡ºä¸€æ®µè‡ªç„¶çš„ä¸­æ–‡å›æ‡‰ã€‚
è«‹é¿å…åˆ—é»ã€æ ¼å¼åŒ–ã€éæ–¼æ­£å¼çš„ç”¨è©ï¼Œä¸è¦æ•™å­¸èªæ°£ï¼Œä¹Ÿä¸è¦å•å¤ªå¤šå•é¡Œï¼Œåªéœ€å›ä¸€å¥è‡ªç„¶çš„å›ç­”å³å¯ã€‚
è«‹ä»¥{tone}èªæ°£å›æ‡‰ï¼Œç›´æ¥èªªä¸­æ–‡ï¼š"""

    # 8. ç”¢ç”Ÿ Gemini å›æ‡‰
    reply = safe_generate(prompt)
    # 9. å„²å­˜å°è©±ç´€éŒ„
    save_chat_log(text, reply)
    # 10. å„²å­˜å–®ç¨çš„æ–‡å­—/èªéŸ³æƒ…ç·’ç´€éŒ„ï¼ˆéå¤šæ¨¡æ…‹ï¼‰
    save_emotion_log(text_emotion, audio_emotion)

    # 11. å°‡ Gemini å›æ‡‰æ¨é€åˆ° message_queueï¼Œè®“ Android ç«¯å¯å–å¾—
    message_queue.append({'action': 'speak', 'text': reply})

    # 12. æ’­æ”¾ Gemini å›æ‡‰èªéŸ³
    await play_response(reply)

    # 13. å›å‚³æœ¬æ¬¡å°è©±èˆ‡æƒ…ç·’çµæœ
    return {
        "reply": reply,
        "text_emotion": text_emotion,
        "audio_emotion": audio_emotion
    }

>>>>>>> cdde5e3fc6d7bae51be920ccbd20fd218dfdeea1
def handle_schedule_input(text):
    """
    å¾æ–‡å­—ä¸­æå–æ™‚ç¨‹è³‡è¨Šä¸¦è¨˜éŒ„åˆ° JSON æª”æ¡ˆã€‚
    """
<<<<<<< HEAD
    # å…ˆå˜—è©¦è§£æç›¸å°æ™‚é–“
    parsed_time = parse_relative_time(text)
    
    if parsed_time:
        # å¦‚æœæˆåŠŸè§£ææ™‚é–“ï¼Œä½¿ç”¨è§£æçµæœ
        prompt = f"""
è«‹å¾ä¸‹åˆ—å¥å­ä¸­æ“·å–è³‡è¨Šä¸¦ä»¥ JSON æ ¼å¼å›è¦†ï¼Œæ¬„ä½åç¨±è«‹ä½¿ç”¨è‹±æ–‡ï¼ˆtask, location, place, personï¼‰ï¼š
- taskï¼šå…·é«”çš„ä»»å‹™å‹•ä½œï¼ˆä¾‹å¦‚ï¼šåƒè—¥ã€ç¡è¦ºã€èµ·åºŠã€åƒé£¯ã€é–‹æœƒç­‰ï¼‰ï¼Œä¸è¦åŒ…å«"æé†’"ã€"è¨˜å¾—"ç­‰è©
- locationï¼šå…·é«”åœ°é»ï¼ˆå¦‚æœæ²’æåˆ°å°±å¡« nullï¼‰
- placeï¼šåœ°é»åˆ†é¡ï¼ˆå¦‚æœæ²’æåˆ°å°±å¡« nullï¼‰
- personï¼šèª°çš„è¡Œç¨‹ï¼ˆæ²’æåˆ°å°±å¡«ã€Œæˆ‘ã€ï¼‰
æ™‚é–“å·²è§£æç‚ºï¼š{parsed_time}
è«‹åªå›å‚³ JSONï¼Œä¸è¦åŠ èªªæ˜æˆ–æ›è¡Œã€‚

ç¯„ä¾‹ï¼š
ã€Œ11:38åˆ†è¨˜å¾—æé†’æˆ‘åƒè—¥ã€â†’ {{"task": "åƒè—¥", "location": null, "place": null, "person": "æˆ‘"}}
ã€Œæ˜å¤©9é»é–‹æœƒã€â†’ {{"task": "é–‹æœƒ", "location": null, "place": null, "person": "æˆ‘"}}

å¥å­ï¼šã€Œ{text}ã€
"""
        
        reply = safe_generate(prompt)

        if not reply:
            print("Gemini æ²’æœ‰å›æ‡‰ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚")
            return

        if reply.startswith("```"):
            reply = reply.strip("`").replace("json", "").strip()

        try:
            data = json.loads(reply)
            data["time"] = parsed_time  # ä½¿ç”¨æˆ‘å€‘è§£æçš„æ™‚é–“
                
        except:
            print(f"å›å‚³æ ¼å¼éŒ¯èª¤ï¼Œç„¡æ³•è§£æï¼š{reply}")
            return

        schedules = load_json(SCHEDULE_FILE)
        data["timestamp"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        schedules.append(data)
        save_json(SCHEDULE_FILE, schedules)

        print(f"å·²å®‰æ’ï¼š{data.get('person', 'æˆ‘')} åœ¨ {data.get('time', 'æœªæŒ‡å®šæ™‚é–“')} è¦ã€Œ{data.get('task', 'æœªçŸ¥ä»»å‹™')}ã€@{data.get('location', 'æœªçŸ¥åœ°é»')}")
        
        # å¦‚æœæœ‰å…·é«”æ™‚é–“ï¼Œé¡¯ç¤ºæé†’è¨­ç½®ä¿¡æ¯
        if data.get('time'):
            try:
                remind_time = datetime.strptime(data['time'], "%Y-%m-%d %H:%M")
                now = datetime.now()
                if remind_time > now:
                    time_diff = remind_time - now
                    hours = int(time_diff.total_seconds() // 3600)
                    minutes = int((time_diff.total_seconds() % 3600) // 60)
                    print(f"å°‡åœ¨ {hours}å°æ™‚{minutes}åˆ†é˜å¾Œæé†’ä½ ")
            except:
                pass
    else:
        # å¦‚æœç„¡æ³•è§£ææ™‚é–“ï¼Œæç¤ºç”¨æˆ¶é‡æ–°è¼¸å…¥
        print(" æŠ±æ­‰ï¼Œæˆ‘ç„¡æ³•ç†è§£æ‚¨æŒ‡å®šçš„æ™‚é–“æ ¼å¼ã€‚")
        print("è«‹ä½¿ç”¨ä»¥ä¸‹æ ¼å¼ï¼š")
        print("- ç›¸å°æ™‚é–“ï¼šã€Œç­‰ç­‰20åˆ†æé†’æˆ‘åƒè—¥ã€")
        print("- å…·é«”æ™‚é–“ï¼šã€Œæ™šä¸Š7é»48åˆ†æé†’æˆ‘åƒè—¥ã€ã€ã€Œæ˜å¤©9é»é–‹æœƒã€")
        print("- ä»Šå¤©æ™‚é–“ï¼šã€Œä»Šå¤©ä¸‹åˆ3é»é–‹æœƒã€")
        return

def vad_record_audio(samplerate=None, max_silence=1.2, min_voice=0.5, max_record=10):
    """
    èªéŸ³æ´»å‹•åµæ¸¬éŒ„éŸ³ï¼šåµæ¸¬åˆ°èªªè©±è‡ªå‹•é–‹å§‹éŒ„éŸ³ï¼Œèªªå®Œè©±è‡ªå‹•çµæŸã€‚
    - max_silence: åµæ¸¬åˆ°é€™éº¼å¤šç§’çš„éœéŸ³å°±çµæŸéŒ„éŸ³
    - min_voice: è‡³å°‘åµæ¸¬åˆ°é€™éº¼å¤šç§’çš„èªéŸ³æ‰ç®—æœ‰æ•ˆ
    - max_record: æœ€é•·éŒ„éŸ³ç§’æ•¸
    """
    if samplerate is None:
        samplerate = AUDIO_SAMPLE_RATE

    print("\nå¾…æ©Ÿä¸­ï¼Œè«‹é–‹å§‹èªªè©±...ï¼ˆè‡ªå‹•åµæ¸¬èªéŸ³ï¼Œèªªå®Œè‡ªå‹•çµæŸï¼‰")
    threshold = 500  # éŸ³é‡é–€æª»ï¼Œè¦–éº¥å…‹é¢¨èª¿æ•´
    silence_count = 0
    voice_count = 0
    frames = []
    blocksize = int(0.1 * samplerate)  # æ¯0.1ç§’å–æ¨£

    def callback(indata, frames_count, time_info, status):
        nonlocal silence_count, voice_count, frames
        volume = np.abs(indata).mean()
        if volume > threshold:
            frames.append(indata.copy())
            silence_count = 0
            voice_count += 0.1
        else:
            if voice_count > 0:
                frames.append(indata.copy())
            silence_count += 0.1

    with sd.InputStream(samplerate=samplerate, channels=1, dtype='int16', blocksize=blocksize, callback=callback):
        total_time = 0
        while True:
            time.sleep(0.1)
            total_time += 0.1
            if voice_count >= min_voice and silence_count >= max_silence:
                break
            if total_time > max_record:
                break

    if voice_count < min_voice:
        print("æœªåµæ¸¬åˆ°æœ‰æ•ˆèªéŸ³ï¼Œè«‹å†è©¦ä¸€æ¬¡ã€‚")
        return False

    audio = np.concatenate(frames, axis=0)
    write(AUDIO_PATH, samplerate, audio)
    print("âœ… éŒ„éŸ³å®Œæˆä¸¦å·²ä¿å­˜")
    return True

# â”€â”€â”€â”€â”€â”€â”€ ä¸»ç¨‹å¼ â”€â”€â”€â”€â”€â”€â”€
async def main():
    print("Gemini å¤šæ¨¡æ…‹æƒ…ç·’æ„ŸçŸ¥åŠ©ç†å•Ÿå‹•")
    from emotion_config import print_config_status
    print_config_status()
    start_reminder_system()
    print("=== æ™ºèƒ½èªéŸ³æ¨¡å¼ ===")
    print("å¾…æ©Ÿä¸­ï¼Œè«‹ç›´æ¥èªªè©±ï¼ˆåµæ¸¬åˆ°èªéŸ³è‡ªå‹•éŒ„éŸ³ï¼‰")
    print("çµæŸè«‹æŒ‰ Ctrl+C")
    while True:
        recording_success = vad_record_audio()
        if not recording_success:
            continue
=======
    relative_time = parse_relative_time(text)
    prompt = f"""
è«‹å¾ä¸‹åˆ—å¥å­ä¸­æ“·å–è³‡è¨Šä¸¦ä»¥ JSON æ ¼å¼å›è¦†ï¼Œæ¬„ä½åç¨±è«‹ä½¿ç”¨è‹±æ–‡ï¼ˆtask, location, place, time, personï¼‰ï¼š
- taskï¼šä»»å‹™ï¼ˆä¾‹å¦‚ å»åƒé£¯ï¼‰
- locationï¼šå…·é«”åœ°é»ï¼ˆä¾‹å¦‚ å°åŒ—è»Šç«™ï¼‰
- placeï¼šåœ°é»åˆ†é¡ï¼ˆä¾‹å¦‚ é¤å»³ï¼‰
- timeï¼šè«‹ä½¿ç”¨ 24 å°æ™‚åˆ¶ YYYY-MM-DD HH:mm æ ¼å¼
- personï¼šèª°çš„è¡Œç¨‹ï¼ˆæ²’æåˆ°å°±å¡«ã€Œæˆ‘ã€ï¼‰
å¦‚æœå¥å­ä¸­åŒ…å«ç›¸å°æ™‚é–“ï¼ˆå¦‚ï¼šæ˜å¤©ã€å¾Œå¤©ã€å¤§å¾Œå¤©ç­‰ï¼‰ï¼Œè«‹ä½¿ç”¨ä»¥ä¸‹æ™‚é–“ï¼š
{relative_time if relative_time else "è«‹æ ¹æ“šå¥å­ä¸­çš„æ™‚é–“æè¿°ä¾†è¨­å®š"}
è«‹åªå›å‚³ JSONï¼Œä¸è¦åŠ èªªæ˜æˆ–æ›è¡Œã€‚
å¥å­ï¼šã€Œ{text}ã€
"""
    reply = safe_generate(prompt)

    if not reply:
        print("Gemini æ²’æœ‰å›æ‡‰ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚")
        return

    if reply.startswith("```"):
        reply = reply.strip("`").replace("json", "").strip()

    try:
        data = json.loads(reply)
    except:
        print(f"å›å‚³æ ¼å¼éŒ¯èª¤ï¼Œç„¡æ³•è§£æï¼š{reply}")
        return

    schedules = load_json(SCHEDULE_FILE)
    data["timestamp"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    schedules.append(data)
    save_json(SCHEDULE_FILE, schedules)

    print(f"å·²å®‰æ’ï¼š{data.get('person', 'æˆ‘')} åœ¨ {data.get('time', 'æœªæŒ‡å®šæ™‚é–“')} è¦ã€Œ{data.get('task', 'æœªçŸ¥ä»»å‹™')}ã€@{data.get('location', 'æœªçŸ¥åœ°é»')}ï¼ˆ{data.get('place', '')}ï¼‰")

@app.route('/face', methods=['POST'])
def face_control():
    data = request.get_json()
    action = data.get('action')
    text = data.get('text', '')
    # æ–°æŒ‡ä»¤åŠ å…¥ä½‡åˆ—
    message_queue.append({'action': action, 'text': text})
    print(f"æ”¶åˆ°è‡‰éƒ¨æ§åˆ¶æŒ‡ä»¤: {action}, å…§å®¹: {text}")
    return jsonify({'status': 'ok', 'received_action': action})

@app.route('/next_message', methods=['GET'])
def next_message():
    if message_queue:
        msg = message_queue.pop(0)
        return jsonify(msg)
    else:
        return jsonify(None)

# â”€â”€â”€â”€â”€â”€â”€ ä¸»ç¨‹å¼ â”€â”€â”€â”€â”€â”€â”€
async def main():
    print("Gemini è²æ§åŠ©ç†å•Ÿå‹•ï¼Œèªªè©±è¼¸å…¥ï¼Œè¼¸å…¥ q æˆ– exit é›¢é–‹ã€‚")
    while True:
        record_audio()
>>>>>>> cdde5e3fc6d7bae51be920ccbd20fd218dfdeea1
        user_input = transcribe_audio()
        if not user_input:
            continue
        print(f"ä½ ï¼ˆèªéŸ³ï¼‰ï¼š{user_input}")
        if user_input.lower() in ["q", "exit"]:
            break
<<<<<<< HEAD

        # ä½¿ç”¨ AI æ™ºèƒ½åˆ¤æ–·ç”¨æˆ¶æ„åœ–
        intent = detect_user_intent(user_input)
        print(f"æ„åœ–åˆ¤æ–·ï¼š{['', 'èŠå¤©å°è©±', 'è¨˜éŒ„ç‰©å“', 'å®‰æ’æé†’', 'æŸ¥è©¢ç‰©å“', 'æ™‚é–“æŸ¥è©¢'][intent] if intent <= 5 else 'æœªçŸ¥'}")
        
        if intent == 1:  # èŠå¤©å°è©±
            result = await chat_with_emotion(user_input, AUDIO_PATH)
            print(f"Geminiï¼š{result['reply']}")
            print(f"ä½¿ç”¨è€…æ–‡å­—æƒ…ç·’ï¼š{result['text_emotion']}")
            print(f"ä½¿ç”¨è€…èªéŸ³æƒ…ç·’ï¼š{result['audio_emotion']}")
            
        elif intent == 2:  # è¨˜éŒ„ç‰©å“ä½ç½®
            print("æª¢æ¸¬åˆ°ç‰©å“è¨˜éŒ„èªå¥ï¼Œè¨˜éŒ„ä¸­...")
            await handle_item_input(user_input)  # ä¿®æ­£ï¼šåŠ  await
            print("ç‰©å“è¨˜éŒ„å®Œæˆ")
            reply = f"å¥½çš„ï¼Œæˆ‘è¨˜ä½äº†ä½ çš„{user_input.replace('æ”¾åœ¨', 'æ”¾åœ¨').replace('æ”¾åˆ°', 'æ”¾åˆ°')}"
            print(f"Geminiï¼š{reply}")
            save_chat_log(user_input, reply)
        elif intent == 3:  # å®‰æ’æ™‚ç¨‹æé†’
            print("æª¢æ¸¬åˆ°è¡Œç¨‹å®‰æ’èªå¥ï¼Œè¨˜éŒ„ä¸­...")
            handle_schedule_input(user_input)
            print("è¡Œç¨‹å®‰æ’å®Œæˆ")
            reply = f"å¥½çš„ï¼Œæˆ‘å·²ç¶“å¹«ä½ è¨˜éŒ„äº†ï¼Œåˆ°æ™‚å€™æœƒæé†’ä½ å–”ï¼"
            print(f"Geminiï¼š{reply}")
            save_chat_log(user_input, reply)
            await play_response(reply) 
        elif intent == 4:  # æŸ¥è©¢ç‰©å“ä½ç½®
            print(" æª¢æ¸¬åˆ°ç‰©å“æŸ¥è©¢èªå¥ï¼ŒæŸ¥è©¢ä¸­...")
            query_result = handle_item_query(user_input)
            print(f"æŸ¥è©¢çµæœï¼š{query_result}")
            print(f"Geminiï¼š{query_result}")
            save_chat_log(user_input, query_result)
            await play_response(query_result)  # GeminièªéŸ³æ’­å ±æŸ¥è©¢çµæœ

            # é€²å…¥æŸ¥æ‰¾å¾ªç’°
            while True:
                follow_up_q = "ä½ æœ‰æ‰¾åˆ°é€™å€‹æ±è¥¿å—ï¼Ÿ"
                print(follow_up_q)
                await play_response(follow_up_q)

                # èªéŸ³è¼¸å…¥
                recording_success = vad_record_audio()
                if not recording_success:
                    continue
                follow_up = transcribe_audio()
                if not follow_up:
                    continue
                follow_up = follow_up.strip().lower()
                # æ–°å¢ï¼šå¦‚æœç”¨æˆ¶èªªä¸ç”¨äº†ã€è¬è¬ã€ä¸æ‰¾äº†ç­‰ï¼Œç›´æ¥éŠœæ¥ä¸€èˆ¬èŠå¤©
                if any(word in follow_up for word in ["ä¸ç”¨", "ä¸ç”¨äº†", "è¬è¬", "ä¸æ‰¾äº†", "ç®—äº†", "æ²’é—œä¿‚", "no", "n"]):
                    msg = "å¥½çš„ï¼Œå¦‚æœæœ‰å…¶ä»–éœ€è¦ï¼Œéš¨æ™‚å‘Šè¨´æˆ‘ã€‚"
                    print(f"Geminiï¼š{msg}")
                    await play_response(msg)
                    # éŠœæ¥ä¸€èˆ¬èŠå¤©
                    result = await chat_with_emotion(user_input, AUDIO_PATH)
                    print(f"Geminiï¼š{result['reply']}")
                    break
                if any(word in follow_up for word in ["æœ‰", "æ‰¾åˆ°äº†", "yes", "y"]):
                    msg = "å¤ªå¥½äº†ï¼è¨˜å¾—ç”¨å®Œæ”¾å›åŸä½ã€‚å¦‚æœé‚„æœ‰å…¶ä»–éœ€è¦ï¼Œéš¨æ™‚å‘Šè¨´æˆ‘ã€‚é‚„æœ‰ä»€éº¼æˆ‘å¯ä»¥å¹«å¿™çš„å—ï¼Ÿ"
                    print(f"Geminiï¼š{msg}")
                    await play_response(msg)
                    break  # éŠœæ¥ä¸€èˆ¬èŠå¤©
                elif any(word in follow_up for word in ["æ²’æœ‰", "æ²’æ‰¾åˆ°"]):
                    # å†è¿½å•æ˜¯å¦è¦å»ºè­°å…¶ä»–åœ°é»
                    ask_more = "è¦ä¸è¦æˆ‘å†å¹«ä½ æƒ³æƒ³å¯èƒ½æœƒæ”¾åœ¨å“ªè£¡ï¼Ÿ"
                    print(f"Geminiï¼š{ask_more}")
                    await play_response(ask_more)
                    recording_success = vad_record_audio()
                    if not recording_success:
                        continue
                    more_reply = transcribe_audio()
                    if not more_reply:
                        continue
                    more_reply = more_reply.strip().lower()
                    # æ–°å¢ï¼šå¦‚æœç”¨æˆ¶èªªä¸ç”¨äº†ã€è¬è¬ã€ä¸æ‰¾äº†ç­‰ï¼Œç›´æ¥éŠœæ¥ä¸€èˆ¬èŠå¤©
                    if any(word in more_reply for word in ["ä¸ç”¨", "ä¸ç”¨äº†", "è¬è¬", "ä¸æ‰¾äº†", "ç®—äº†", "æ²’é—œä¿‚", "no", "n"]):
                        msg = "å¥½çš„ï¼Œå¦‚æœæœ‰å…¶ä»–éœ€è¦ï¼Œéš¨æ™‚å‘Šè¨´æˆ‘ã€‚"
                        print(f"Geminiï¼š{msg}")
                        await play_response(msg)
                        result = await chat_with_emotion(user_input, AUDIO_PATH)
                        print(f"Geminiï¼š{result['reply']}")
                        break
                    if any(word in more_reply for word in ["å¥½", "å¯ä»¥", "yes", "y"]):
                        # å»ºè­°å¸¸è¦‹åœ°é»
                        suggestion = "ä½ å¯ä»¥å†å»æµ´å®¤ã€å®¢å»³ã€åºŠé ­æ«ƒã€å»šæˆ¿ã€æ›¸æˆ¿ç­‰åœ°æ–¹æ‰¾æ‰¾çœ‹ã€‚"
                        print(f"Geminiï¼š{suggestion}")
                        await play_response(suggestion)
                        # æœƒå†å›åˆ° while å¾ªç’°ç¹¼çºŒå•ã€Œæœ‰æ‰¾åˆ°å—ã€
                        continue
                    else:
                        # å…¶ä»–å›ç­”ï¼Œç¹¼çºŒå¾ªç’°
                        continue
                else:
                    msg = "å¥½çš„ï¼Œå¦‚æœæœ‰éœ€è¦éš¨æ™‚å‘Šè¨´æˆ‘ã€‚"
                    print(f"Geminiï¼š{msg}")
                    await play_response(msg)
                    break
        elif intent == 5:  # æ™‚é–“æŸ¥è©¢ - æ–°å¢è™•ç†
            print(" æª¢æ¸¬åˆ°æ™‚é–“æŸ¥è©¢ï¼Œæœ¬åœ°è™•ç†ä¸­...")
            time_response = handle_time_query(user_input)
            print(f"Geminiï¼š{time_response}")
            save_chat_log(user_input, time_response)
        else:  # å‚™ç”¨æ–¹æ¡ˆ
            result = await chat_with_emotion(user_input, AUDIO_PATH)
            print(f"Geminiï¼š{result['reply']}")
            print(f"æ–‡å­—æƒ…ç·’ï¼š{result['text_emotion']}")
            print(f"èªéŸ³æƒ…ç·’ï¼š{result['audio_emotion']}")
        
        print("\n" + "="*50)  # åˆ†éš”ç·š
            
    print("åŠ©ç†å·²é—œé–‰ï¼Œå†è¦‹ï¼")

if __name__ == "__main__":
    import asyncio
=======
        result = await chat_with_emotion(user_input, AUDIO_PATH)
        print(f"Geminiï¼š{result['reply']}")
        print(f"æ–‡å­—æƒ…ç·’ï¼š{result['text_emotion']}")
        print(f"èªéŸ³æƒ…ç·’ï¼š{result['audio_emotion']}")

if __name__ == "__main__":
    import threading
    import asyncio
    # å•Ÿå‹• Flask ä¼ºæœå™¨æ–¼èƒŒæ™¯åŸ·è¡Œ
    flask_thread = threading.Thread(target=app.run, kwargs={'host': '0.0.0.0', 'port': 5000}, daemon=True)
    flask_thread.start()
    # å•Ÿå‹•ä¸»ç¨‹å¼
>>>>>>> cdde5e3fc6d7bae51be920ccbd20fd218dfdeea1
    asyncio.run(main())
